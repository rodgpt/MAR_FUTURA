{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodgpt/MAR_FUTURA/blob/main/Boat%20Detector/Agile/RunModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fcc207b",
      "metadata": {
        "id": "2fcc207b"
      },
      "source": [
        "# RunModel\n",
        "\n",
        "This notebook embeds all WAV files in a folder into a Hoplite DB, loads a previously-trained AGILE linear classifier, and writes an inference CSV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "916c174f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "916c174f",
        "outputId": "266126e1-2573-43ba-91ad-cc82042c5d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/google-research/perch-hoplite.git\n",
            "  Cloning https://github.com/google-research/perch-hoplite.git to /tmp/pip-req-build-n4j9jdqw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google-research/perch-hoplite.git /tmp/pip-req-build-n4j9jdqw\n",
            "  Resolved https://github.com/google-research/perch-hoplite.git to commit e468adb45b6531e734649122bf7cf596527ce64e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py<2.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from perch-hoplite==1.0.0.dev1) (1.4.0)\n",
            "Requirement already satisfied: etils<2.0.0,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from etils[epath]<2.0.0,>=1.5.0->perch-hoplite==1.0.0.dev1) (1.13.0)\n",
            "Requirement already satisfied: imageio<3.0.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from perch-hoplite==1.0.0.dev1) (2.37.2)\n",
            "Requirement already satisfied: ipywidgets<9.0,>=8.1 in /usr/local/lib/python3.12/dist-packages (from perch-hoplite==1.0.0.dev1) (8.1.8)\n",
            "Requirement already satisfied: kagglehub<0.4,>=0.3 in /usr/local/lib/python3.12/dist-packages (from perch-hoplite==1.0.0.dev1) (0.3.13)\n",
            "Requirement already satisfied: librosa<0.12,>=0.11 in /usr/local/lib/python3.12/dist-packages (from perch-hoplite==1.0.0.dev1) (0.11.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.6.1 in /usr/local/lib/python3.12/dist-packages (from perch-hoplite==1.0.0.dev1) (3.10.0)\n",
            "Requirement already satisfied: ml-collections<0.2.0,>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from perch-hoplite==1.0.0.dev1) (0.1.1)\n",
            "Requirement already satisfied: notebook<8.0,>=7.4 in /usr/local/lib/python3.12/dist-packages (from perch-hoplite==1.0.0.dev1) (7.5.2)\n",
            "Requirement already satisfied: numpy<3.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from perch-hoplite==1.0.0.dev1) (2.0.2)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (2.2.2)\n",
            "Requirement already satisfied: usearch<3.0,>=2.17 in /usr/local/lib/python3.12/dist-packages (from perch-hoplite==1.0.0.dev1) (2.23.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[epath]<2.0.0,>=1.5.0->perch-hoplite==1.0.0.dev1) (2026.1.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath]<2.0.0,>=1.5.0->perch-hoplite==1.0.0.dev1) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from etils[epath]<2.0.0,>=1.5.0->perch-hoplite==1.0.0.dev1) (4.15.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath]<2.0.0,>=1.5.0->perch-hoplite==1.0.0.dev1) (3.23.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0.0,>=2.5.0->perch-hoplite==1.0.0.dev1) (12.1.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (0.2.3)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (4.0.15)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (3.0.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub<0.4,>=0.3->perch-hoplite==1.0.0.dev1) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub<0.4,>=0.3->perch-hoplite==1.0.0.dev1) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub<0.4,>=0.3->perch-hoplite==1.0.0.dev1) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub<0.4,>=0.3->perch-hoplite==1.0.0.dev1) (4.67.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (0.63.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (5.2.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (1.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.6.1->perch-hoplite==1.0.0.dev1) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.6.1->perch-hoplite==1.0.0.dev1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.6.1->perch-hoplite==1.0.0.dev1) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.6.1->perch-hoplite==1.0.0.dev1) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.6.1->perch-hoplite==1.0.0.dev1) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.6.1->perch-hoplite==1.0.0.dev1) (2.9.0.post0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from ml-collections<0.2.0,>=0.1.1->perch-hoplite==1.0.0.dev1) (1.17.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.12/dist-packages (from ml-collections<0.2.0,>=0.1.1->perch-hoplite==1.0.0.dev1) (21.6.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (2.14.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in /usr/local/lib/python3.12/dist-packages (from notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (2.28.0)\n",
            "Requirement already satisfied: jupyterlab<4.6,>=4.5.2 in /usr/local/lib/python3.12/dist-packages (from notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (4.5.2)\n",
            "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /usr/local/lib/python3.12/dist-packages (from notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.2.4)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (6.5.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.1->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.1->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (2025.3)\n",
            "Requirement already satisfied: gcsfs>=2022.11.0 in /usr/local/lib/python3.12/dist-packages (from pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (2026.1.0)\n",
            "Requirement already satisfied: pandas-gbq>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (0.33.0)\n",
            "Requirement already satisfied: simsimd<7.0.0,>=6.0.5 in /usr/local/lib/python3.12/dist-packages (from usearch<3.0,>=2.17->perch-hoplite==1.0.0.dev1) (6.5.12)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (3.13.3)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (2.43.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.2.2)\n",
            "Requirement already satisfied: google-cloud-storage>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (3.7.0)\n",
            "Requirement already satisfied: google-cloud-storage-control in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (0.19.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (4.9.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (4.12.1)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (25.1.0)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (3.1.6)\n",
            "Requirement already satisfied: jupyter-client>=7.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (7.4.9)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (5.9.1)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.23.1)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (26.2.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (2.0.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (1.9.0)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab<4.6,>=4.5.2->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (2.0.5)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab<4.6,>=4.5.2->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.28.1)\n",
            "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab<4.6,>=4.5.2->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (6.17.1)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab<4.6,>=4.5.2->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (2.3.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.13.0)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (4.26.0)\n",
            "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (0.46.0)\n",
            "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.5.0)\n",
            "Requirement already satisfied: pyarrow>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (22.0.0)\n",
            "Requirement already satisfied: pydata-google-auth>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.9.1)\n",
            "Requirement already satisfied: psutil>=5.9.8 in /usr/local/lib/python3.12/dist-packages (from pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (7.2.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (2.29.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0,>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (3.40.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (4.5.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub<0.4,>=0.3->perch-hoplite==1.0.0.dev1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub<0.4,>=0.3->perch-hoplite==1.0.0.dev1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub<0.4,>=0.3->perch-hoplite==1.0.0.dev1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub<0.4,>=0.3->perch-hoplite==1.0.0.dev1) (2026.1.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (2.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.22.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (25.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa<0.12,>=0.11->perch-hoplite==1.0.0.dev1) (2.23)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.15.0->pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.15.0->pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (6.33.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.15.0->pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.27.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (2.0.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery<4.0.0,>=3.20.0->pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery<4.0.0,>=3.20.0->pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (2.8.0)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=3.7.0->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.8.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab<4.6,>=4.5.2->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab<4.6,>=4.5.2->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.2->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (1.8.15)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.2->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (1.6.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (0.8.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.30.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.4)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (4.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (3.2.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (2.21.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets<9.0,>=8.1->perch-hoplite==1.0.0.dev1) (0.2.14)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage-control->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.76.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage-control->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (0.14.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (1.4.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery<4.0.0,>=3.20.0->pandas-gbq>=0.19.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (1.76.0)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (25.10.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2022.11.0->pandas[gcp]<3.0.0,>=2.1.1->perch-hoplite==1.0.0.dev1) (3.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (2.8.1)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook<8.0,>=7.4->perch-hoplite==1.0.0.dev1) (1.4.0)\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Using cached flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (6.33.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
            "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (12.1.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Using cached werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m930.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.5-py3-none-any.whl (225 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorboard-data-server, google_pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.12.19 google_pasta-0.2.0 libclang-18.1.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 werkzeug-3.1.5 wheel-0.45.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# @title Imports\n",
        "!pip install git+https://github.com/google-research/perch-hoplite.git\n",
        "!pip install tensorflow\n",
        "from etils import epath\n",
        "import os\n",
        "\n",
        "from perch_hoplite.agile import audio_loader\n",
        "from perch_hoplite.agile import classifier\n",
        "from perch_hoplite.agile import colab_utils\n",
        "from perch_hoplite.agile import embed\n",
        "from perch_hoplite.agile import source_info\n",
        "from perch_hoplite.agile.classifier import LinearClassifier\n",
        "from perch_hoplite.zoo import model_configs\n",
        "from pathlib import Path\n",
        "import shutil # Import shutil for file operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "77880be5",
      "metadata": {
        "id": "77880be5",
        "outputId": "03ac5b28-09e6-42e9-b529-100084e7482a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found embeddings cache on Drive. Restoring embeddings DB to local disk...\n",
            "Embeddings restored. Skipping audio staging.\n",
            "Copying classifier checkpoint locally...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command '['cp', '-f', '/content/drive/Shareddrives/MAR FUTURA/Hydrophones/BOAT DETECTOR AGILE/agile_classifier_v2.pt', '/content/run_matanzas_32/model/agile_classifier_v2.pt']' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4139116433.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m# Copy classifier weights locally (small optimization; not the main bottleneck)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Copying classifier checkpoint locally...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_path_drive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----- Paths -----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['cp', '-f', '/content/drive/Shareddrives/MAR FUTURA/Hydrophones/BOAT DETECTOR AGILE/agile_classifier_v2.pt', '/content/run_matanzas_32/model/agile_classifier_v2.pt']' returned non-zero exit status 1."
          ]
        }
      ],
      "source": [
        "# @title Configuration (COLAB ONLY) - Prefer embeddings cache, otherwise stage audio\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# -----------------------------\n",
        "# DRIVE PATHS (source of truth)\n",
        "# -----------------------------\n",
        "input_audio_dir_drive = \"/content/drive/Shareddrives/Hydrophones/Matanzas/13-11-25/32\"\n",
        "classifier_path_drive = \"/content/drive/Shareddrives/MAR FUTURA/Hydrophones/agile_classifier_v2.pt\"\n",
        "output_csv_drive = f\"{input_audio_dir_drive}/inference.csv\"\n",
        "\n",
        "# Embeddings cache folder on Drive (you can rename, but keep it stable)\n",
        "# Recommendation: encode model+sharding in the folder name to avoid accidental mismatch.\n",
        "emb_cache_drive = f\"{input_audio_dir_drive}/_agile_db\" ##Check\n",
        "\n",
        "# -----------------------------\n",
        "# LOCAL PATHS (fast I/O)\n",
        "# -----------------------------\n",
        "run_root = \"/content/run_matanzas_32\"\n",
        "input_audio_dir = f\"{run_root}/audio\"     # LOCAL staged audio (only used if cache missing)\n",
        "db_path = f\"{run_root}/db\"                # LOCAL embeddings DB (restored or created)\n",
        "classifier_path = f\"{run_root}/model/agile_classifier_v2.pt\"  # LOCAL model copy\n",
        "output_csv_filepath = f\"{run_root}/inference.csv\"             # LOCAL output\n",
        "\n",
        "# Create local directories\n",
        "Path(db_path).mkdir(parents=True, exist_ok=True)\n",
        "Path(classifier_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "Path(output_csv_filepath).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Ensure Drive cache directory exists\n",
        "Path(emb_cache_drive).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def drive_cache_nonempty(cache_dir: str) -> bool:\n",
        "    \"\"\"True if cache_dir exists and contains at least one file.\"\"\"\n",
        "    if not os.path.isdir(cache_dir):\n",
        "        return False\n",
        "    for root, _, files in os.walk(cache_dir):\n",
        "        if files:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Flags used later (main run cell) to decide whether to sync DB back to Drive\n",
        "embeddings_restored_from_drive = False\n",
        "\n",
        "# -----------------------------\n",
        "# STAGE DATA: Prefer embeddings cache -> local\n",
        "# -----------------------------\n",
        "if drive_cache_nonempty(emb_cache_drive):\n",
        "    print(\"Found embeddings cache on Drive. Restoring embeddings DB to local disk...\")\n",
        "    # Clear local DB folder to avoid mixing old/new artifacts\n",
        "    subprocess.run([\"bash\", \"-lc\", f\"rm -rf '{db_path}'/*\"], check=True)\n",
        "\n",
        "    # Restore embeddings cache to local db_path\n",
        "    subprocess.run([\n",
        "        \"rsync\", \"-a\", \"--info=progress2\",\n",
        "        emb_cache_drive.rstrip(\"/\") + \"/\",\n",
        "        db_path.rstrip(\"/\") + \"/\",\n",
        "    ], check=True)\n",
        "\n",
        "    # IMPORTANT: do NOT stage audio in this branch\n",
        "    print(\"Embeddings restored. Skipping audio staging.\")\n",
        "    staged_audio = False\n",
        "    embeddings_restored_from_drive = True\n",
        "\n",
        "else:\n",
        "    print(\"No embeddings cache found on Drive. Staging WAV files to local disk so we can embed...\")\n",
        "    Path(input_audio_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    subprocess.run([\n",
        "        \"rsync\", \"-a\", \"--info=progress2\", \"--prune-empty-dirs\",\n",
        "        \"--include=*/\", \"--include=*.wav\", \"--include=*.WAV\",\n",
        "        \"--exclude=*\",\n",
        "        input_audio_dir_drive.rstrip(\"/\") + \"/\",\n",
        "        input_audio_dir.rstrip(\"/\") + \"/\",\n",
        "    ], check=True)\n",
        "\n",
        "    staged_audio = True\n",
        "\n",
        "# Copy classifier weights locally (small optimization; not the main bottleneck)\n",
        "print(\"Copying classifier checkpoint locally...\")\n",
        "subprocess.run([\"cp\", \"-f\", classifier_path_drive, classifier_path], check=True)\n",
        "\n",
        "print(\"----- Paths -----\")\n",
        "print(\"input_audio_dir_drive:\", input_audio_dir_drive)\n",
        "print(\"emb_cache_drive:\", emb_cache_drive)\n",
        "print(\"input_audio_dir (LOCAL):\", input_audio_dir)\n",
        "print(\"db_path (LOCAL):\", db_path)\n",
        "print(\"classifier_path (LOCAL):\", classifier_path)\n",
        "print(\"output_csv_filepath (LOCAL):\", output_csv_filepath)\n",
        "print(\"output_csv_drive:\", output_csv_drive)\n",
        "print(\"staged_audio:\", staged_audio)\n",
        "print(\"embeddings_restored_from_drive:\", embeddings_restored_from_drive)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bc1b620",
      "metadata": {
        "id": "2bc1b620"
      },
      "outputs": [],
      "source": [
        "# @title Configuration (LOCAL ONLY)\n",
        "\n",
        "# Run this cell only if you're running locally.\n",
        "\n",
        "# -----------------------------\n",
        "# PATHS (Local)\n",
        "# -----------------------------\n",
        "\n",
        "# Example (external drive / Drive File Stream / etc.)\n",
        "# IMPORTANT: If this points to Google Drive / cloud-synced storage, local runs may be slow\n",
        "# because files are fetched on-demand. Enable LOCAL_STAGING below to copy WAVs to your\n",
        "# local SSD before embedding.\n",
        "input_audio_dir = \"/Volumes/Untitled\"\n",
        "\n",
        "# Embeddings DB folder\n",
        "db_path = \"/Volumes/Untitled/_agile_db\"\n",
        "\n",
        "# Output CSV path\n",
        "output_csv_filepath = \"/Volumes/Untitled/inference.csv\"\n",
        "\n",
        "# Trained classifier path\n",
        "classifier_path = \"agile_classifier_v2.pt\"\n",
        "#\n",
        "\n",
        "# NOTE: After running either the Colab cell or the Local cell, always run the Common configuration cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cda96219",
      "metadata": {
        "id": "cda96219",
        "outputId": "d6f549df-d073-4211-8297-9aa419b46429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_audio_dir: /Volumes/Untitled\n",
            "db_path: /Volumes/Untitled/_agile_db\n",
            "classifier_path: agile_classifier_v2.pt\n",
            "output_csv_filepath: /Volumes/Untitled/inference.csv\n",
            "audio_worker_threads: 8\n",
            "embed_batch_size: 32\n",
            "logit_threshold: 2\n",
            "min_consecutive_segments: 2\n"
          ]
        }
      ],
      "source": [
        "# @title Configuration (COMMON - ALWAYS RUN)\n",
        "\n",
        "# Run this cell after you run either the Colab-only config cell OR the Local-only config cell.\n",
        "\n",
        "# -----------------------------\n",
        "# USER SETTINGS\n",
        "# -----------------------------\n",
        "\n",
        "dataset_name = 'RunDataset'\n",
        "dataset_fileglob = '*.[wW][aA][vV]'\n",
        "\n",
        "# Embedding model choice MUST match how you embedded when you trained the classifier.\n",
        "model_choice = 'perch_8'\n",
        "\n",
        "# Optional sharding (keep consistent with training if possible).\n",
        "use_file_sharding = True\n",
        "shard_length_in_seconds = 5\n",
        "\n",
        "# Performance knobs\n",
        "# - audio_worker_threads: parallel audio loading/processing\n",
        "# - embed_batch_size: how many sources are queued per dispatch\n",
        "# If you overload your machine, lower these.\n",
        "audio_worker_threads = 8\n",
        "embed_batch_size = 32\n",
        "\n",
        "# Inference threshold. Higher => fewer detections.\n",
        "logit_threshold = 2\n",
        "labels = None\n",
        "\n",
        "# File-level rule: require at least N consecutive windows above threshold\n",
        "min_consecutive_segments = 2\n",
        "\n",
        "# -----------------------------\n",
        "# VALIDATE REQUIRED PATHS\n",
        "# -----------------------------\n",
        "\n",
        "_required = ['input_audio_dir', 'db_path', 'output_csv_filepath', 'classifier_path']\n",
        "_missing = [k for k in _required if k not in globals() or not globals()[k]]\n",
        "if _missing:\n",
        "  raise RuntimeError(\n",
        "      'Missing required path variables from the Colab-only or Local-only configuration cell: '\n",
        "      + ', '.join(_missing)\n",
        "  )\n",
        "\n",
        "# Create directories (safe even if they already exist)\n",
        "Path(output_csv_filepath).parent.mkdir(parents=True, exist_ok=True)\n",
        "Path(db_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# CREATE CONFIGS\n",
        "# -----------------------------\n",
        "\n",
        "audio_glob = source_info.AudioSourceConfig(\n",
        "    dataset_name=dataset_name,\n",
        "    base_path=input_audio_dir,\n",
        "    file_glob=dataset_fileglob,\n",
        "    min_audio_len_s=1.0,\n",
        "    target_sample_rate_hz=-2,\n",
        "    shard_len_s=float(shard_length_in_seconds) if use_file_sharding else None,\n",
        ")\n",
        "\n",
        "configs = colab_utils.load_configs(\n",
        "    source_info.AudioSources((audio_glob,)),\n",
        "    db_path,\n",
        "    model_config_key=model_choice,\n",
        "    db_key='sqlite_usearch',\n",
        ")\n",
        "\n",
        "# Correcting the model handle for surfperch\n",
        "if model_choice == 'surfperch':\n",
        "  configs.model_config.model_config.tfhub_path = 'google/surfperch/1'\n",
        "\n",
        "print('input_audio_dir:', input_audio_dir)\n",
        "print('db_path:', configs.db_config.db_config.db_path)\n",
        "print('classifier_path:', classifier_path)\n",
        "print('output_csv_filepath:', output_csv_filepath)\n",
        "print('audio_worker_threads:', audio_worker_threads)\n",
        "print('embed_batch_size:', embed_batch_size)\n",
        "print('logit_threshold:', logit_threshold)\n",
        "print('min_consecutive_segments:', min_consecutive_segments)\n",
        "\n",
        "if 'output_csv_drive' in globals() and output_csv_drive:\n",
        "  print('output_csv_drive:', output_csv_drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20844b98",
      "metadata": {
        "id": "20844b98",
        "outputId": "dfb0bfcd-a0fc-4283-a9bc-5fe9d877e2df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_audio_dir exists: True is_dir: True\n",
            "WAV files found under input_audio_dir (recursive): 15256\n",
            "WAV examples: ['/Volumes/Untitled/20251211_112600.WAV', '/Volumes/Untitled/20251211_112800.WAV', '/Volumes/Untitled/20251211_113000.WAV']\n",
            "Initialized DB located at /Volumes/Untitled/_agile_db\n",
            "Embedding dataset: RunDataset\n",
            "Existing embeddings in DB: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 430/15256 [00:20<11:15, 21.95it/s]"
          ]
        }
      ],
      "source": [
        "#@title Embed folder, load classifier, and run inference\n",
        "\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Sanity checks: make sure input_audio_dir exists and contains WAVs.\n",
        "# This prevents a silent 0it embed run when the folder is empty / not mounted / fileglob mismatch.\n",
        "\n",
        "audio_root = Path(str(input_audio_dir))\n",
        "print('input_audio_dir exists:', audio_root.exists(), 'is_dir:', audio_root.is_dir())\n",
        "\n",
        "if not audio_root.exists() or not audio_root.is_dir():\n",
        "    raise RuntimeError(f\"input_audio_dir is not a readable directory: {input_audio_dir}\")\n",
        "\n",
        "try:\n",
        "    wavs_lower = list(audio_root.rglob('*.wav'))\n",
        "    wavs_upper = list(audio_root.rglob('*.WAV'))\n",
        "    _wav_count = len(wavs_lower) + len(wavs_upper)\n",
        "    _wav_examples = [str(p) for p in (wavs_lower[:3] + wavs_upper[:3])]\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Failed while scanning for WAVs under input_audio_dir={input_audio_dir}: {e}\")\n",
        "\n",
        "print('WAV files found under input_audio_dir (recursive):', _wav_count)\n",
        "if _wav_examples:\n",
        "    print('WAV examples:', _wav_examples[:5])\n",
        "\n",
        "# NOTE: perch-hoplite file_glob is applied relative to base_path. If your WAVs are in nested\n",
        "# subfolders and you see 0 embeddings, you may need dataset_fileglob like '**/*.[wW][aA][vV]'.\n",
        "if _wav_count == 0:\n",
        "    raise RuntimeError(\n",
        "        f\"No WAV files found under input_audio_dir={input_audio_dir}. \"\n",
        "        \"Check the path/mount, or update dataset_fileglob (e.g. '**/*.[wW][aA][vV]') if files are in subfolders.\"\n",
        "    )\n",
        "\n",
        "# 1) Connect/create DB (per configs from prior cell)\n",
        "db = configs.db_config.load_db()\n",
        "print('Initialized DB located at', configs.db_config.db_config.db_path)\n",
        "\n",
        "# 2) Embed all files in the folder (skip if DB already non-empty)\n",
        "print(f'Embedding dataset: {audio_glob.dataset_name}')\n",
        "worker = embed.EmbedWorker(\n",
        "    audio_sources=configs.audio_sources_config,\n",
        "    db=db,\n",
        "    model_config=configs.model_config,\n",
        "    audio_worker_threads=int(audio_worker_threads),\n",
        ")\n",
        "\n",
        "existing = db.count_embeddings()\n",
        "print('Existing embeddings in DB:', existing)\n",
        "\n",
        "did_embed = False\n",
        "\n",
        "if existing == 0:\n",
        "    worker.process_all(\n",
        "        target_dataset_name=audio_glob.dataset_name,\n",
        "        batch_size=int(embed_batch_size),\n",
        "    )\n",
        "    did_embed = True\n",
        "    print('Embedding complete, total embeddings:', db.count_embeddings())\n",
        "else:\n",
        "    print('Skipping embedding because DB is non-empty. Delete the db_path folder to force re-embed.')\n",
        "\n",
        "# 2a) If local DB staging is enabled, sync the staged DB back to the source RIGHT AFTER embedding.\n",
        "# This way if the notebook stops before classification finishes, you still keep the embeddings.\n",
        "_local_db_synced_back_early = False\n",
        "if (\n",
        "    did_embed\n",
        "    and '_LOCAL_DB_STAGING_ENABLED' in globals()\n",
        "    and _LOCAL_DB_STAGING_ENABLED\n",
        "    and 'SYNC_DB_BACK_TO_SOURCE_ON_FINISH' in globals()\n",
        "    and SYNC_DB_BACK_TO_SOURCE_ON_FINISH\n",
        "    and '_LOCAL_DB_SRC_PATH' in globals()\n",
        "    and _LOCAL_DB_SRC_PATH\n",
        "):\n",
        "    try:\n",
        "        Path(_LOCAL_DB_SRC_PATH).mkdir(parents=True, exist_ok=True)\n",
        "        print('Syncing staged DB back to source db_path (early):', _LOCAL_DB_SRC_PATH)\n",
        "        subprocess.run(\n",
        "            [\n",
        "                'rsync',\n",
        "                '-a',\n",
        "                '--progress',\n",
        "                str(db_path).rstrip('/') + '/',\n",
        "                str(_LOCAL_DB_SRC_PATH).rstrip('/') + '/',\n",
        "            ],\n",
        "            check=True,\n",
        "        )\n",
        "        _local_db_synced_back_early = True\n",
        "        print('Done syncing DB back to source (early).')\n",
        "    except Exception as e:\n",
        "        print('WARN: early DB sync-back failed:', e)\n",
        "\n",
        "# 2b) If running in Colab, persist the local DB back to Drive cache\n",
        "# (Otherwise, /content is ephemeral and you will lose embeddings on runtime reset.)\n",
        "if did_embed and 'emb_cache_drive' in globals() and emb_cache_drive:\n",
        "    print('Syncing embeddings DB back to Drive cache:', emb_cache_drive)\n",
        "    Path(emb_cache_drive).mkdir(parents=True, exist_ok=True)\n",
        "    subprocess.run(\n",
        "        [\n",
        "            'rsync',\n",
        "            '-a',\n",
        "            '--progress',\n",
        "            str(db_path).rstrip('/') + '/',\n",
        "            str(emb_cache_drive).rstrip('/') + '/',\n",
        "        ],\n",
        "        check=True,\n",
        "    )\n",
        "    print('Done syncing embeddings cache to Drive.')\n",
        "\n",
        "# 3) Load embedding model (needed for audio loader in some workflows; kept for parity)\n",
        "db_model_config = db.get_metadata('model_config')\n",
        "embed_config = db.get_metadata('audio_sources')\n",
        "model_class = model_configs.get_model_class(db_model_config.model_key)\n",
        "embedding_model = model_class.from_config(db_model_config.model_config)\n",
        "audio_sources = source_info.AudioSources.from_config_dict(embed_config)\n",
        "window_size_s = getattr(embedding_model, 'window_size_s', 5.0)\n",
        "_ = audio_loader.make_filepath_loader(\n",
        "    audio_sources=audio_sources,\n",
        "    window_size_s=window_size_s,\n",
        "    sample_rate_hz=embedding_model.sample_rate,\n",
        ")\n",
        "\n",
        "# 4) Load trained classifier and write inference CSV (window-level)\n",
        "linear_classifier = LinearClassifier.load(classifier_path)\n",
        "\n",
        "output_csv_all_logits_filepath = str(\n",
        "    Path(output_csv_filepath).with_name(Path(output_csv_filepath).stem + '_all_logits.csv')\n",
        ")\n",
        "\n",
        "classifier.write_inference_csv(\n",
        "    linear_classifier,\n",
        "    db,\n",
        "    output_csv_all_logits_filepath,\n",
        "    -1.0e9,\n",
        "    labels=labels,\n",
        ")\n",
        "print('Done. Wrote ALL window logits CSV:', output_csv_all_logits_filepath)\n",
        "\n",
        "classifier.write_inference_csv(\n",
        "    linear_classifier,\n",
        "    db,\n",
        "    output_csv_filepath,\n",
        "    logit_threshold,\n",
        "    labels=labels,\n",
        ")\n",
        "print('Done. Wrote FILTERED window-level CSV:', output_csv_filepath)\n",
        "\n",
        "# 5) Post-process: per-file \"boat\" decision requires consecutive windows\n",
        "# This produces a file-level CSV next to the window-level CSV.\n",
        "import pandas as pd\n",
        "\n",
        "score_col = None\n",
        "file_level_csv = str(Path(output_csv_filepath).with_name(Path(output_csv_filepath).stem + '_filelevel.csv'))\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(output_csv_filepath)\n",
        "except FileNotFoundError:\n",
        "    raise\n",
        "\n",
        "if df.empty:\n",
        "    print('Inference CSV was empty; skipping file-level post-processing.')\n",
        "else:\n",
        "    # Be tolerant to either 'logit' or 'logits'\n",
        "    for c in ('logit', 'logits', 'score', 'prob', 'probability'):\n",
        "        if c in df.columns:\n",
        "            score_col = c\n",
        "            break\n",
        "\n",
        "    if score_col is None:\n",
        "        raise RuntimeError('Could not find a score column in inference CSV. Expected one of: logit, logits, score, prob, probability')\n",
        "\n",
        "    # Focus label if present\n",
        "    if 'label' in df.columns:\n",
        "        df = df[df['label'].astype(str) == 'boat']\n",
        "\n",
        "    if df.empty:\n",
        "        print('No rows for label=boat in inference CSV; writing empty file-level CSV.')\n",
        "        pd.DataFrame(columns=['filename', 'best_score', 'segments_over_threshold', 'longest_consecutive', 'is_boat']).to_csv(file_level_csv, index=False)\n",
        "    else:\n",
        "        df['window_start'] = pd.to_numeric(df.get('window_start'), errors='coerce')\n",
        "        df[score_col] = pd.to_numeric(df[score_col], errors='coerce')\n",
        "\n",
        "        df = df.dropna(subset=['filename', 'window_start', score_col]).copy()\n",
        "\n",
        "        def longest_run(starts, step):\n",
        "            starts = sorted(set(starts))\n",
        "            if not starts:\n",
        "                return 0\n",
        "            eps = max(1e-6, abs(step) * 1e-6)\n",
        "            best = 1\n",
        "            cur = 1\n",
        "            for i in range(1, len(starts)):\n",
        "                if abs((starts[i] - starts[i-1]) - step) <= eps:\n",
        "                    cur += 1\n",
        "                else:\n",
        "                    best = max(best, cur)\n",
        "                    cur = 1\n",
        "            return max(best, cur)\n",
        "\n",
        "        rows = []\n",
        "        step = float(shard_length_in_seconds)\n",
        "        thr = float(logit_threshold)\n",
        "        min_cons = int(min_consecutive_segments)\n",
        "\n",
        "        for fname, g in df.groupby('filename'):\n",
        "            over = g[g[score_col] >= thr]\n",
        "            starts_over = over['window_start'].dropna().tolist()\n",
        "            lr = longest_run(starts_over, step)\n",
        "            best = float(g[score_col].max()) if not g.empty else None\n",
        "            cnt = int(len(starts_over))\n",
        "            is_boat = lr >= min_cons\n",
        "            rows.append({\n",
        "                'filename': fname,\n",
        "                'best_score': best,\n",
        "                'segments_over_threshold': cnt,\n",
        "                'longest_consecutive': lr,\n",
        "                'is_boat': bool(is_boat),\n",
        "            })\n",
        "\n",
        "        out_df = pd.DataFrame(rows).sort_values(['is_boat', 'best_score'], ascending=[False, False])\n",
        "        out_df.to_csv(file_level_csv, index=False)\n",
        "        print('Wrote file-level CSV:', file_level_csv)\n",
        "\n",
        "# 6) Optionally copy output CSV back to Drive (only if configured)\n",
        "if 'output_csv_drive' in globals() and output_csv_drive:\n",
        "    print('Copying inference CSV back to Drive...')\n",
        "    subprocess.run(['cp', '-f', output_csv_filepath, output_csv_drive], check=True)\n",
        "    print('Done. Wrote:', output_csv_drive)\n",
        "\n",
        "# 7) If local DB staging is enabled, optionally sync the staged DB back to the original source folder.\n",
        "# If the early sync already happened, this is redundant but safe.\n",
        "_local_db_synced_back = _local_db_synced_back_early\n",
        "if (\n",
        "    (not _local_db_synced_back)\n",
        "    and '_LOCAL_DB_STAGING_ENABLED' in globals()\n",
        "    and _LOCAL_DB_STAGING_ENABLED\n",
        "    and 'SYNC_DB_BACK_TO_SOURCE_ON_FINISH' in globals()\n",
        "    and SYNC_DB_BACK_TO_SOURCE_ON_FINISH\n",
        "    and '_LOCAL_DB_SRC_PATH' in globals()\n",
        "    and _LOCAL_DB_SRC_PATH\n",
        "):\n",
        "    try:\n",
        "        Path(_LOCAL_DB_SRC_PATH).mkdir(parents=True, exist_ok=True)\n",
        "        print('Syncing staged DB back to source db_path:', _LOCAL_DB_SRC_PATH)\n",
        "        subprocess.run(\n",
        "            [\n",
        "                'rsync',\n",
        "                '-a',\n",
        "                '--progress',\n",
        "                str(db_path).rstrip('/') + '/',\n",
        "                str(_LOCAL_DB_SRC_PATH).rstrip('/') + '/',\n",
        "            ],\n",
        "            check=True,\n",
        "        )\n",
        "        _local_db_synced_back = True\n",
        "        print('Done syncing DB back to source.')\n",
        "    except Exception as e:\n",
        "        print('WARN: failed to sync DB back to source:', e)\n",
        "\n",
        "# 8) Optional cleanup of local staging folder (audio/model/db)\n",
        "# If DB staging was enabled but sync-back failed, skip cleanup so you don't lose the staged DB.\n",
        "_skip_cleanup = (\n",
        "    '_LOCAL_DB_STAGING_ENABLED' in globals()\n",
        "    and _LOCAL_DB_STAGING_ENABLED\n",
        "    and 'SYNC_DB_BACK_TO_SOURCE_ON_FINISH' in globals()\n",
        "    and SYNC_DB_BACK_TO_SOURCE_ON_FINISH\n",
        "    and not _local_db_synced_back\n",
        ")\n",
        "\n",
        "if _skip_cleanup:\n",
        "    print('WARN: skipping cleanup because DB sync-back did not succeed. Staged DB preserved at:', db_path)\n",
        "\n",
        "if (\n",
        "    not _skip_cleanup\n",
        "    and 'CLEANUP_LOCAL_STAGING_ON_FINISH' in globals()\n",
        "    and CLEANUP_LOCAL_STAGING_ON_FINISH\n",
        "    and '_LOCAL_STAGING_RUN_ROOT' in globals()\n",
        "    and _LOCAL_STAGING_RUN_ROOT\n",
        "    and (\n",
        "        ('_LOCAL_AUDIO_STAGING_ENABLED' in globals() and _LOCAL_AUDIO_STAGING_ENABLED)\n",
        "        or ('_LOCAL_DB_STAGING_ENABLED' in globals() and _LOCAL_DB_STAGING_ENABLED)\n",
        "    )\n",
        "):\n",
        "    import shutil\n",
        "    try:\n",
        "        print('Cleaning up local staged folder:', _LOCAL_STAGING_RUN_ROOT)\n",
        "        shutil.rmtree(_LOCAL_STAGING_RUN_ROOT, ignore_errors=True)\n",
        "        print('Cleanup complete.')\n",
        "    except Exception as e:\n",
        "        print('WARN: cleanup failed:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97fe266b",
      "metadata": {
        "id": "97fe266b"
      },
      "outputs": [],
      "source": [
        "#@title Plot detections over time (detections/hour)\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "csv_path = output_csv_filepath\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "print('rows:', len(df))\n",
        "print('columns:', list(df.columns))\n",
        "\n",
        "# Optional: focus on one label (e.g. boat). Set to None to include all labels.\n",
        "focus_label = 'boat'\n",
        "if focus_label and 'label' in df.columns:\n",
        "  df = df[df['label'] == focus_label]\n",
        "\n",
        "# Parse datetime from filename like YYYYMMDD_HHMMSS(.WAV)\n",
        "# Example: ZAPALLAR_20241122_143550_5sec.wav -> 20241122_143550\n",
        "_dt_re = re.compile(r'(\\d{8})_(\\d{6})')\n",
        "\n",
        "def extract_dt(fname: str):\n",
        "  m = _dt_re.search(str(fname))\n",
        "  if not m:\n",
        "    return pd.NaT\n",
        "  return pd.to_datetime(m.group(1) + m.group(2), format='%Y%m%d%H%M%S', errors='coerce')\n",
        "\n",
        "df['file_dt'] = df['filename'].apply(extract_dt)\n",
        "\n",
        "# If window_start exists, shift timestamp by that many seconds.\n",
        "if 'window_start' in df.columns:\n",
        "  df['window_start'] = pd.to_numeric(df['window_start'], errors='coerce')\n",
        "  df['dt'] = df['file_dt'] + pd.to_timedelta(df['window_start'].fillna(0), unit='s')\n",
        "else:\n",
        "  df['dt'] = df['file_dt']\n",
        "\n",
        "# Drop rows where we can't parse time\n",
        "plot_df = df.dropna(subset=['dt']).copy()\n",
        "if plot_df.empty:\n",
        "  raise RuntimeError('No rows had a parseable datetime in filename. Adjust extract_dt() regex/format.')\n",
        "\n",
        "plot_df = plot_df.set_index('dt').sort_index()\n",
        "\n",
        "detections_per_hour = plot_df['idx'].resample('1H').count()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "detections_per_hour.plot()\n",
        "plt.title(f'Detections per hour' + (f\" ({focus_label})\" if focus_label else ''))\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Detections / hour')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Optional: show daily totals too\n",
        "show_daily = True\n",
        "\n",
        "if show_daily:\n",
        "  daily = plot_df['idx'].resample('1D').count()\n",
        "  plt.figure(figsize=(12, 4))\n",
        "  daily.plot()\n",
        "  plt.title(f'Detections per day' + (f\" ({focus_label})\" if focus_label else ''))\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel('Detections / day')\n",
        "  plt.grid(True, alpha=0.3)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}