{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JHLOpq-bNwx2",
        "outputId": "70e1c9c0-d59a-45d5-83a3-23cbfeae9802"
      },
      "outputs": [],
      "source": [
        "#@title Only run this code if you need to install perch-hoplite\n",
        "\n",
        "# For running in Colab (only if perch-hoplite is not installed)\n",
        "# !pip install git+https://github.com/google-research/perch-hoplite.git\n",
        "\n",
        "# For running locally\n",
        "# Install perch-hoplite in your local environment (e.g. venv/conda) before running this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhzspl0UN2QO",
        "outputId": "89a9068b-9773-49b8-ac92-bb3ec8743b92"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipywidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwidgets\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m colab_utils\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m embed\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m source_info\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CODES/.venv311/lib/python3.11/site-packages/perch_hoplite/agile/colab_utils.py:22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01metils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m epath\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_collections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_dict\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m embed\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m source_info\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m db_loader\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CODES/.venv311/lib/python3.11/site-packages/perch_hoplite/agile/embed.py:30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m source_info\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interface \u001b[38;5;28;01mas\u001b[39;00m hoplite_interface\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mzoo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model_configs\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mzoo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m zoo_interface\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msoundfile\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CODES/.venv311/lib/python3.11/site-packages/perch_hoplite/zoo/model_configs.py:23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_collections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_dict\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mzoo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hub\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mperch_hoplite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mzoo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m zoo_interface\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mModelConfigName\u001b[39;00m(enum.Enum):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CODES/.venv311/lib/python3.11/site-packages/perch_hoplite/zoo/hub.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33;03m\"\"\"Wrapper for loading models from KaggleHub with backwards compatibility.\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkagglehub\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Older model configs may contain a full model URL, as we used with TFHub.\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# These are kept for back-compat, and converted to Kaggle Models slugs.\u001b[39;00m\n\u001b[32m     23\u001b[39m PERCH_TF_HUB_URL = (\n\u001b[32m     24\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhttps://www.kaggle.com/models/google/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbird-vocalization-classifier/frameworks/TensorFlow2/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mvariations/bird-vocalization-classifier/versions\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     27\u001b[39m )\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "# @title Imports\n",
        "from etils import epath\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from perch_hoplite.agile import colab_utils\n",
        "from perch_hoplite.agile import embed\n",
        "from perch_hoplite.agile import source_info\n",
        "from perch_hoplite.db import brutalism\n",
        "from perch_hoplite.db import interface\n",
        "import os\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from perch_hoplite.agile import audio_loader\n",
        "from perch_hoplite.agile import classifier\n",
        "from perch_hoplite.agile import classifier_data\n",
        "from perch_hoplite.agile import embedding_display\n",
        "from perch_hoplite.agile import source_info\n",
        "from perch_hoplite.db  import brutalism\n",
        "from perch_hoplite.db import score_functions\n",
        "from perch_hoplite.db  import search_results\n",
        "from perch_hoplite.db import sqlite_usearch_impl\n",
        "from perch_hoplite.zoo import model_configs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKtoEYbnN4Mu",
        "outputId": "4fb8b1c2-e067-4997-a309-9e7ee357a974"
      },
      "outputs": [],
      "source": [
        "# @title Configuration { vertical-output: true }\n",
        "\n",
        "# @markdown Configure the raw dataset and output location(s).  The format is a mapping from\n",
        "# @markdown a dataset_name to a (base_path, fileglob) pair.  Note that the file\n",
        "# @markdown globs are case sensitive.  The dataset name can be anything you want.\n",
        "#\n",
        "# @markdown This structure allows you to move your data around without having to\n",
        "# @markdown re-embed the dataset.  The generated embedding database will be\n",
        "# @markdown placed in the base path. This allows you to simply swap out\n",
        "# @markdown the base path here if you ever move your dataset.\n",
        "\n",
        "# @markdown By default we only process one dataset at a time.  Re-run this entire notebook\n",
        "# @markdown once per dataset.\n",
        "\n",
        "# @markdown For example, we might set dataset_base_path to '/home/me/myproject',\n",
        "# @markdown and use the glob '\\*/\\*.wav' if all of the audio files have filepaths\n",
        "# @markdown like '/home/me/myproject/site_XYZ/audio_ABC.wav' (e.g. audio files are contained in subfolders of the base directory).\n",
        "\n",
        "# -----------------------------\n",
        "# PATHS (Local vs Colab)\n",
        "# -----------------------------\n",
        "\n",
        "# For running locally (Rod)\n",
        "base_agile_path = epath.Path(\n",
        "    \"/Users/Rodrigo/Library/CloudStorage/GoogleDrive-royanedel@marfutura.org/Mi unidad/Agile\"\n",
        ")\n",
        "\n",
        "# For running in Colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# base_agile_path = epath.Path(\"/content/drive/Shareddrives/MAR FUTURA/Agile\")\n",
        "\n",
        "# -----------------------------\n",
        "# USER SETTINGS\n",
        "# -----------------------------\n",
        "\n",
        "# 1. Create a unique name for the database that will store the embeddings for the target data.\n",
        "dataset_name = 'Data'  # @param {type:'string'}\n",
        "\n",
        "# 2. Input the filepath for the folder that is containing the input audio files.\n",
        "dataset_base_path = str(base_agile_path / 'Data2')  #@param {type:'string'}\n",
        "\n",
        "# 3. Input the file pattern for the audio files within that folder that you want to embed.\n",
        "dataset_fileglob = '*.wav'  # @param {type:'string'}\n",
        "\n",
        "# 4. [Optional] If saving the embeddings database to a new directory, specify here.\n",
        "db_path = ''  # @param {type:'string'}\n",
        "if not db_path or db_path == 'None':\n",
        "  db_path = None\n",
        "\n",
        "# If you want a default DB location, keep this enabled.\n",
        "if db_path is None:\n",
        "  db_path = str(base_agile_path / 'Data')\n",
        "\n",
        "# 5. Choose a supported model to generate embeddings.\n",
        "model_choice = 'perch_8'  #@param['perch_v2','perch_8', 'humpback', 'multispecies_whale', 'surfperch', 'birdnet_V2.3']\n",
        "\n",
        "# 6. [Optional] Shard the audio for embeddings.\n",
        "use_file_sharding = True  # @param {type:'boolean'}\n",
        "shard_length_in_seconds = 5  # @param {type:'number'}\n",
        "\n",
        "audio_glob = source_info.AudioSourceConfig(\n",
        "    dataset_name=dataset_name,\n",
        "    base_path=dataset_base_path,\n",
        "    file_glob=dataset_fileglob,\n",
        "    min_audio_len_s=1.0,\n",
        "    target_sample_rate_hz=-2,\n",
        "    shard_len_s=float(shard_length_in_seconds) if use_file_sharding else None,\n",
        ")\n",
        "\n",
        "configs = colab_utils.load_configs(\n",
        "    source_info.AudioSources((audio_glob,)),\n",
        "    db_path,\n",
        "    model_config_key=model_choice,\n",
        "    db_key='sqlite_usearch',\n",
        ")\n",
        "\n",
        "# Correcting the model handle for surfperch\n",
        "if model_choice == 'surfperch':\n",
        "  configs.model_config.model_config.tfhub_path = 'google/surfperch/1'\n",
        "\n",
        "# Convenience paths used later\n",
        "query_uri_default = str(base_agile_path / 'Data' / 'boat.wav')\n",
        "output_csv_default = str(base_agile_path / 'Data' / 'samples.csv')\n",
        "\n",
        "print('dataset_base_path:', dataset_base_path)\n",
        "print('db_path:', db_path)\n",
        "print('query_uri_default:', query_uri_default)\n",
        "print('output_csv_default:', output_csv_default)\n",
        "\n",
        "configs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i57MNkbqN6-a",
        "outputId": "cc684d39-9fde-4e07-972f-70083c33b64c"
      },
      "outputs": [],
      "source": [
        "#@title Initialize the hoplite database (DB) { vertical-output: true }\n",
        "global db\n",
        "db = configs.db_config.load_db()\n",
        "num_embeddings = db.count_embeddings()\n",
        "\n",
        "print('Initialized DB located at ', configs.db_config.db_config.db_path)\n",
        "\n",
        "def drop_and_reload_db(_) -> interface.HopliteDBInterface:\n",
        "  db_path = epath.Path(configs.db_config.db_config.db_path)\n",
        "  for fp in db_path.glob('hoplite.sqlite*'):\n",
        "    fp.unlink()\n",
        "  (db_path / 'usearch.index').unlink()\n",
        "  print('\\n Deleted previous db at: ', configs.db_config.db_config.db_path)\n",
        "  db = configs.db_config.load_db()\n",
        "\n",
        "#@markdown If `drop_existing_db` set to True, when the database already exists and contains embeddings,\n",
        "#@markdown then those existing embeddings will be erased. You will be prompted to confirm you wish to delete those existing\n",
        "#@markdown embeddings. If you want to keep existing embeddings in the database, then set to False, which will append the new\n",
        "#@markdown embeddings to the database.\n",
        "drop_existing_db = True  #@param {type:'boolean'}\n",
        "\n",
        "if num_embeddings > 0 and drop_existing_db:\n",
        "  print('Existing DB contains datasets: ', db.get_dataset_names())\n",
        "  print('num embeddings: ', num_embeddings)\n",
        "  print('\\n\\nClick the button below to confirm you really want to drop the database at ')\n",
        "  print(f'{configs.db_config.db_config.db_path}\\n')\n",
        "  print(f'This will permanently delete all {num_embeddings} embeddings from the existing database.\\n')\n",
        "  print('If you do NOT want to delete this data, set `drop_existing_db` above to `False` and re-run this cell.\\n')\n",
        "\n",
        "  button = widgets.Button(description='Delete database?')\n",
        "  button.on_click(drop_and_reload_db)\n",
        "  display(button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a9b8kL_jN-qp",
        "outputId": "a95ed3dd-c889-4cae-efab-e48a249d81c4"
      },
      "outputs": [],
      "source": [
        "#@title Run the embedding { vertical-output: true }\n",
        "\n",
        "print(f'Embedding dataset: {audio_glob.dataset_name}')\n",
        "\n",
        "worker = embed.EmbedWorker(\n",
        "    audio_sources=configs.audio_sources_config,\n",
        "    db=db,\n",
        "    model_config=configs.model_config)\n",
        "\n",
        "worker.process_all(target_dataset_name=audio_glob.dataset_name)\n",
        "\n",
        "print('\\n\\nEmbedding complete, total embeddings: ', db.count_embeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oI7_CDwOAoa"
      },
      "outputs": [],
      "source": [
        "#@title Per dataset statistics { vertical-output: true }\n",
        "\n",
        "for dataset in db.get_dataset_names():\n",
        "  print(f'\\nDataset \\'{dataset}\\':')\n",
        "  print('\\tnum embeddings: ', db.get_embeddings_by_source(dataset, source_id=None).shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ5Uh_FMOLw4"
      },
      "outputs": [],
      "source": [
        "#@title Load model and connect to database. { vertical-output: true }\n",
        "\n",
        "#@markdown Location of database containing audio embeddings.\n",
        "db_path = db_path  #@param {type:'string'}\n",
        "#@markdown Identifier (eg, name) to attach to labels produced during validation.\n",
        "annotator_id = 'Rod'  #@param {type:'string'}\n",
        "\n",
        "# Provide a default usearch_cfg if one is not found in the database.\n",
        "# This configuration specifies the dimensionality of the embeddings and the metric used for similarity search.\n",
        "# Assuming 512 dimensions and cosine similarity for a general case.\n",
        "# Note: The actual dimensions should match the model being used.\n",
        "default_usearch_cfg = {'dims': 512, 'metric': 'cos'}\n",
        "\n",
        "# Try to create the database, providing a default config if it doesn't exist.\n",
        "# If the database already exists with metadata, this default config will be ignored.\n",
        "db = sqlite_usearch_impl.SQLiteUsearchDB.create(db_path)\n",
        "\n",
        "db_model_config = db.get_metadata('model_config')\n",
        "embed_config = db.get_metadata('audio_sources')\n",
        "model_class = model_configs.get_model_class(db_model_config.model_key)\n",
        "embedding_model = model_class.from_config(db_model_config.model_config)\n",
        "audio_sources = source_info.AudioSources.from_config_dict(embed_config)\n",
        "if hasattr(embedding_model, 'window_size_s'):\n",
        "  window_size_s = embedding_model.window_size_s\n",
        "else:\n",
        "  window_size_s = 5.0\n",
        "audio_filepath_loader = audio_loader.make_filepath_loader(\n",
        "    audio_sources=audio_sources,\n",
        "    window_size_s=window_size_s,\n",
        "    sample_rate_hz=embedding_model.sample_rate,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LNtVj-vOBCl"
      },
      "outputs": [],
      "source": [
        "#@title Load query audio. { vertical-output: true }\n",
        "\n",
        "#@markdown The `query_uri` can be a URL, filepath, or Xeno-Canto ID\n",
        "#@markdown (like `xc777802`, containing an Eastern Whipbird (`easwhi1`)).\n",
        "query_uri = query_uri_default  # @param {type:'string'}\n",
        "query_label = 'boat'  # @param {type:'string'}\n",
        "\n",
        "query = embedding_display.QueryDisplay(\n",
        "    uri=query_uri, offset_s=0.0, window_size_s=5.0, sample_rate_hz=32000)\n",
        "_ = query.display_interactive()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4bbscp5OQOV"
      },
      "outputs": [],
      "source": [
        "#@title Embed the Query and Search. { vertical-output: true }\n",
        "\n",
        "#@markdown Number of results to find and display.\n",
        "num_results = 50  #@param\n",
        "query_embedding = embedding_model.embed(\n",
        "    query.get_audio_window()).embeddings[0, 0]\n",
        "\n",
        "#@markdown If checked, search for examples\n",
        "#@markdown near a particular target score.\n",
        "target_sampling = False  #@param {type: 'boolean'}\n",
        "\n",
        "#@markdown When target sampling, target this score.\n",
        "target_score = -1.0  #@param\n",
        "if not target_sampling:\n",
        "  target_score = None\n",
        "\n",
        "#@markdown If True, search the full DB. Otherwise, use approximate\n",
        "#@markdown nearest-neighbor search.\n",
        "exact_search = False  #@param {type: 'boolean'}\n",
        "\n",
        "if exact_search:\n",
        "  score_fn = score_functions.get_score_fn('dot', target_score=target_score)\n",
        "  results, all_scores = brutalism.threaded_brute_search(\n",
        "      db, query_embedding, num_results, score_fn=score_fn)\n",
        "  # TODO(tomdenton): Better histogram when target sampling.\n",
        "  _ = plt.hist(all_scores, bins=100)\n",
        "  hit_scores = [r.sort_score for r in results.search_results]\n",
        "  plt.scatter(hit_scores, np.zeros_like(hit_scores), marker='|',\n",
        "              color='r', alpha=0.5)\n",
        "else:\n",
        "  ann_matches = db.ui.search(query_embedding, count=num_results)\n",
        "  results = search_results.TopKSearchResults(top_k=num_results)\n",
        "  for k, d in zip(ann_matches.keys, ann_matches.distances):\n",
        "    results.update(search_results.SearchResult(k, d))\n",
        "\n",
        "display(results) # Add this line to display the search results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-bFnHIkRN97"
      },
      "outputs": [],
      "source": [
        "#@title Display Results. { vertical-output: true }\n",
        "\n",
        "display_results = embedding_display.EmbeddingDisplayGroup.from_search_results(\n",
        "    results, db, sample_rate_hz=32000, frame_rate=100,\n",
        "    audio_loader=audio_filepath_loader)\n",
        "display_results.display(positive_labels=[query_label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzQmYY8HR3Ez"
      },
      "outputs": [],
      "source": [
        "#@title Save data labels. { vertical-output: true }\n",
        "\n",
        "prev_lbls, new_lbls = 0, 0\n",
        "for lbl in display_results.harvest_labels(annotator_id):\n",
        "  check = db.insert_label(lbl, skip_duplicates=True)\n",
        "  new_lbls += check\n",
        "  prev_lbls += (1 - check)\n",
        "print('\\nnew_lbls: ', new_lbls)\n",
        "print('\\nprev_lbls: ', prev_lbls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6LK94jbSeUs"
      },
      "source": [
        "# ***Classify***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCsTRa_BSlpN"
      },
      "outputs": [],
      "source": [
        "#@title Classifier training. { vertical-output: true }\n",
        "\n",
        "#@markdown Set of labels to classify. If None, auto-populated from the DB.\n",
        "target_labels = \"boat\"  #@param {type:\"string\"}\n",
        "if target_labels:\n",
        "  target_labels = [label.strip() for label in target_labels.split(',') if label.strip()]\n",
        "else:\n",
        "    target_labels = None\n",
        "\n",
        "\n",
        "#@markdown Classifier traning hyperparams. These should not require tuning.\n",
        "learning_rate = 1e-3  #@param\n",
        "weak_neg_weight = 0.05  #@param\n",
        "l2_mu = 0.000  #@param\n",
        "num_steps = 128  #@param\n",
        "\n",
        "train_ratio = 0.9  #@param\n",
        "batch_size = 128  #@param\n",
        "weak_negatives_batch_size = 128  #@param\n",
        "loss_fn_name = 'bce'  #@param ['hinge', 'bce']\n",
        "\n",
        "data_manager = classifier_data.AgileDataManager(\n",
        "    target_labels=target_labels,\n",
        "    db=db,\n",
        "    train_ratio=train_ratio,\n",
        "    min_eval_examples=1,\n",
        "    batch_size=batch_size,\n",
        "    weak_negatives_batch_size=weak_negatives_batch_size,\n",
        "    rng=np.random.default_rng(seed=5))\n",
        "\n",
        "print('Training for target labels : ')\n",
        "print(data_manager.get_target_labels())\n",
        "linear_classifier, eval_scores = classifier.train_linear_classifier(\n",
        "    data_manager=data_manager,\n",
        "    learning_rate=learning_rate,\n",
        "    weak_neg_weight=weak_neg_weight,\n",
        "    num_train_steps=num_steps,\n",
        ")\n",
        "print('\\n' + '-' * 80)\n",
        "top1 = eval_scores['top1_acc']\n",
        "print(f'top-1      {top1:.3f}')\n",
        "rocauc = eval_scores['roc_auc']\n",
        "print(f'roc_auc    {rocauc:.3f}')\n",
        "cmap = eval_scores['cmap']\n",
        "print(f'cmap       {cmap:.3f}')\n",
        "\n",
        "# Save linear classifier.\n",
        "linear_classifier.save(os.path.join(db_path, 'agile_classifier_v2.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dEpQfDhTza7"
      },
      "outputs": [],
      "source": [
        "#@title Review Classifier Results. { vertical-output: true }\n",
        "\n",
        "#@markdown Number of results to find and display.\n",
        "target_label = 'boat'  #@param {type:'string'}\n",
        "num_results = 50  #@param\n",
        "\n",
        "target_label_idx = data_manager.get_target_labels().index(target_label)\n",
        "class_query = linear_classifier.beta[:, target_label_idx]\n",
        "bias = linear_classifier.beta_bias[target_label_idx]\n",
        "\n",
        "#@markdown Number of (randomly selected) database entries to search over.\n",
        "sample_size = 1_000_000  #@param\n",
        "\n",
        "#@markdown Whether to use margin-sampling. If checked, search for examples\n",
        "#@markdown with logits near a particular target score (usually 0).\n",
        "margin_sampling = False  #@param {type: 'boolean'}\n",
        "\n",
        "#@markdown When margin sampling, target this logit.\n",
        "margin_target_score = -0.0  #@param\n",
        "if not margin_sampling:\n",
        "  margin_target_score = None\n",
        "score_fn = score_functions.get_score_fn(\n",
        "    'dot', bias=bias, target_score=margin_target_score)\n",
        "results, all_scores = brutalism.threaded_brute_search(\n",
        "    db, class_query, num_results, score_fn=score_fn,\n",
        "    sample_size=sample_size)\n",
        "\n",
        "# TODO(tomdenton): Better histogram when margin sampling.\n",
        "_ = plt.hist(all_scores, bins=100)\n",
        "hit_scores = [r.sort_score for r in results.search_results]\n",
        "plt.scatter(hit_scores, np.zeros_like(hit_scores), marker='|',\n",
        "            color='r', alpha=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDqK4BmXUBx5"
      },
      "outputs": [],
      "source": [
        "#@title Display Results. { vertical-output: true }\n",
        "\n",
        "display_results = embedding_display.EmbeddingDisplayGroup.from_search_results(\n",
        "    results, db, sample_rate_hz=32000, frame_rate=100,\n",
        "    audio_loader=audio_filepath_loader)\n",
        "display_results.display(positive_labels=[target_label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC2RGBDWU49e"
      },
      "outputs": [],
      "source": [
        "#@title Save data labels. { vertical-output: true }\n",
        "\n",
        "prev_lbls, new_lbls = 0, 0\n",
        "for lbl in display_results.harvest_labels(annotator_id):\n",
        "  check = db.insert_label(lbl, skip_duplicates=True)\n",
        "  new_lbls += check\n",
        "  prev_lbls += (1 - check)\n",
        "print('\\nnew_lbls: ', new_lbls)\n",
        "print('\\nprev_lbls: ', prev_lbls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqW78r09U--5"
      },
      "outputs": [],
      "source": [
        "#@title Run inference with trained classifier. { vertical-output: true }\n",
        "\n",
        "output_csv_filepath = output_csv_default  #@param {type:'string'}\n",
        "logit_threshold = 2  #@param\n",
        "# Set labels to a tuple of desired labels if you want to run inference on a\n",
        "# subset of the labels.\n",
        "labels = None  #@param\n",
        "\n",
        "classifier.write_inference_csv(\n",
        "    linear_classifier, db, output_csv_filepath, logit_threshold, labels=labels)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
