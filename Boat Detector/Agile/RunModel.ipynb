{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunModel\\n",
    "\\n",
    "This notebook embeds all WAV files in a folder into a Hoplite DB, loads a previously-trained AGILE linear classifier, and writes an inference CSV.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Imports\\n",
    "from etils import epath\\n",
    "import os\\n",
    "\\n",
    "from perch_hoplite.agile import audio_loader\\n",
    "from perch_hoplite.agile import classifier\\n",
    "from perch_hoplite.agile import colab_utils\\n",
    "from perch_hoplite.agile import embed\\n",
    "from perch_hoplite.agile import source_info\\n",
    "from perch_hoplite.agile.classifier import LinearClassifier\\n",
    "from perch_hoplite.zoo import model_configs\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configuration { vertical-output: true }\\n",
    "\\n",
    "# -----------------------------\\n",
    "# PATHS (Local vs Colab)\\n",
    "# -----------------------------\\n",
    "\\n",
    "# For running locally (Rod)\\n",
    "base_agile_path = epath.Path(\\n",
    "    '/Users/Rodrigo/Library/CloudStorage/GoogleDrive-royanedel@marfutura.org/Mi unidad/Agile'\\n",
    ")\\n",
    "\\n",
    "# For running in Colab\\n",
    "# from google.colab import drive\\n",
    "# drive.mount('/content/drive')\\n",
    "# base_agile_path = epath.Path('/content/drive/Shareddrives/MAR FUTURA/Agile')\\n",
    "\\n",
    "# -----------------------------\\n",
    "# USER SETTINGS\\n",
    "# -----------------------------\\n",
    "\\n",
    "# Folder containing audio to classify.\\n",
    "input_audio_dir = str(base_agile_path / 'Data2')  # @param {type:'string'}\\n",
    "dataset_fileglob = '*.[wW][aA][vV]'  # @param {type:'string'}\\n",
    "dataset_name = 'RunDataset'  # @param {type:'string'}\\n",
    "\\n",
    "# Where to store the embedding DB for this run. Use a new folder to keep runs isolated.\\n",
    "db_path = str(base_agile_path / 'RunDB')  # @param {type:'string'}\\n",
    "\\n",
    "# Saved classifier created in CreateModel.ipynb (LinearClassifier.save).\\n",
    "classifier_path = str(base_agile_path / 'Data' / 'agile_classifier_v2.pt')  # @param {type:'string'}\\n",
    "\\n",
    "# Output CSV path.\\n",
    "output_csv_filepath = str(base_agile_path / 'RunResults' / 'inference.csv')  # @param {type:'string'}\\n",
    "\\n",
    "# Embedding model choice MUST match how you embedded when you trained the classifier.\\n",
    "model_choice = 'perch_8'  #@param['perch_v2','perch_8', 'humpback', 'multispecies_whale', 'surfperch', 'birdnet_V2.3']\\n",
    "\\n",
    "# Optional sharding (keep consistent with training if possible).\\n",
    "use_file_sharding = True  # @param {type:'boolean'}\\n",
    "shard_length_in_seconds = 5  # @param {type:'number'}\\n",
    "\\n",
    "# Inference threshold. Higher => fewer detections.\\n",
    "logit_threshold = 2  # @param\\n",
    "labels = None  # @param\\n",
    "\\n",
    "# Create output folder.\\n",
    "epath.Path(output_csv_filepath).parent.mkdir(parents=True, exist_ok=True)\\n",
    "epath.Path(db_path).mkdir(parents=True, exist_ok=True)\\n",
    "\\n",
    "audio_glob = source_info.AudioSourceConfig(\\n",
    "    dataset_name=dataset_name,\\n",
    "    base_path=input_audio_dir,\\n",
    "    file_glob=dataset_fileglob,\\n",
    "    min_audio_len_s=1.0,\\n",
    "    target_sample_rate_hz=-2,\\n",
    "    shard_len_s=float(shard_length_in_seconds) if use_file_sharding else None,\\n",
    ")\\n",
    "\\n",
    "configs = colab_utils.load_configs(\\n",
    "    source_info.AudioSources((audio_glob,)),\\n",
    "    db_path,\\n",
    "    model_config_key=model_choice,\\n",
    "    db_key='sqlite_usearch',\\n",
    ")\\n",
    "\\n",
    "# Correcting the model handle for surfperch\\n",
    "if model_choice == 'surfperch':\\n",
    "  configs.model_config.model_config.tfhub_path = 'google/surfperch/1'\\n",
    "\\n",
    "print('input_audio_dir:', input_audio_dir)\\n",
    "print('db_path:', db_path)\\n",
    "print('classifier_path:', classifier_path)\\n",
    "print('output_csv_filepath:', output_csv_filepath)\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Embed folder, load classifier, and run inference { vertical-output: true }\\n",
    "\\n",
    "# 1) Connect/create DB\\n",
    "db = configs.db_config.load_db()\\n",
    "print('Initialized DB located at', configs.db_config.db_config.db_path)\\n",
    "\\n",
    "# 2) Embed all files in the folder\\n",
    "print(f'Embedding dataset: {audio_glob.dataset_name}')\\n",
    "worker = embed.EmbedWorker(\\n",
    "    audio_sources=configs.audio_sources_config,\\n",
    "    db=db,\\n",
    "    model_config=configs.model_config,\\n",
    ")\\n",
    "worker.process_all(target_dataset_name=audio_glob.dataset_name)\\n",
    "print('Embedding complete, total embeddings:', db.count_embeddings())\\n",
    "\\n",
    "# 3) Load embedding model (needed for audio loader in some workflows; kept for parity)\\n",
    "db_model_config = db.get_metadata('model_config')\\n",
    "embed_config = db.get_metadata('audio_sources')\\n",
    "model_class = model_configs.get_model_class(db_model_config.model_key)\\n",
    "embedding_model = model_class.from_config(db_model_config.model_config)\\n",
    "audio_sources = source_info.AudioSources.from_config_dict(embed_config)\\n",
    "window_size_s = getattr(embedding_model, 'window_size_s', 5.0)\\n",
    "_ = audio_loader.make_filepath_loader(\\n",
    "    audio_sources=audio_sources,\\n",
    "    window_size_s=window_size_s,\\n",
    "    sample_rate_hz=embedding_model.sample_rate,\\n",
    ")\\n",
    "\\n",
    "# 4) Load trained classifier and write inference CSV\\n",
    "linear_classifier = LinearClassifier.load(classifier_path)\\n",
    "classifier.write_inference_csv(\\n",
    "    linear_classifier,\\n",
    "    db,\\n",
    "    output_csv_filepath,\\n",
    "    logit_threshold,\\n",
    "    labels=labels,\\n",
    ")\\n",
    "print('Done. Wrote:', output_csv_filepath)\\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
