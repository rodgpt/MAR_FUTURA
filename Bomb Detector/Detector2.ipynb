{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "view-in-github",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# Detector2 — Dynamite Fishing Detection System\n",
    "\n",
    "This notebook implements a rule-based prototype for detecting dynamite fishing events\n",
    "in `.wav` files based on the hierarchical framework detailed in *\"Acoustic Signatures\n",
    "of Underwater Explosions: A Technical Report.\"*\n",
    "\n",
    "The detection system uses a three-tiered approach:\n",
    "- **Tier 1:** Initial Event Detection (Candidate Identification)\n",
    "- **Tier 2:** Primary Classification (Explosion Verification)\n",
    "- **Tier 3:** Contextual Filtering (Confuser Rejection)\n",
    "\n",
    "### Data input modes\n",
    "| Mode | Cell to run | Description |\n",
    "|------|------------|-------------|\n",
    "| **Google Drive (mounted)** | *Configuration (COLAB ONLY)* | Mount Drive and point to a folder |\n",
    "| **Google Drive link** | *Configuration (GOOGLE DRIVE LINK)* | Paste a shared Drive link; files are downloaded via `gdown` |\n",
    "| **Local** | *Configuration (LOCAL ONLY)* | Point to a local folder |\n",
    "\n",
    "After running **one** of the configuration cells above, always run the **Configuration (COMMON)** cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-colab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configuration (COLAB ONLY) — Mount Google Drive\n",
    "\n",
    "# Run this cell ONLY in Google Colab when your audio files live on a mounted Drive.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# -----------------------------\n",
    "# DRIVE PATHS (source of truth)\n",
    "# -----------------------------\n",
    "input_audio_dir = \"/content/drive/Shareddrives/MAR FUTURA/Perú/Spanish bombs/Bombs RS\"\n",
    "output_csv_filepath = f\"{input_audio_dir}/explosion_results.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# LOCAL STAGING (optional speed-up)\n",
    "# -----------------------------\n",
    "run_root = \"/content/run_detector2\"\n",
    "staged_audio_dir = f\"{run_root}/audio\"\n",
    "use_local_staging = False  # Set True to rsync WAVs to local SSD first\n",
    "\n",
    "Path(run_root).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if use_local_staging:\n",
    "    import subprocess\n",
    "    Path(staged_audio_dir).mkdir(parents=True, exist_ok=True)\n",
    "    print('Staging WAV files to local disk...')\n",
    "    subprocess.run([\n",
    "        'rsync', '-a', '--info=progress2', '--prune-empty-dirs',\n",
    "        '--include=*/', '--include=*.wav', '--include=*.WAV', '--exclude=*',\n",
    "        input_audio_dir.rstrip('/') + '/',\n",
    "        staged_audio_dir.rstrip('/') + '/',\n",
    "    ], check=True)\n",
    "    input_audio_dir = staged_audio_dir\n",
    "    print('Staging complete.')\n",
    "\n",
    "print('input_audio_dir:', input_audio_dir)\n",
    "print('output_csv_filepath:', output_csv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-gdrive-link",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configuration (GOOGLE DRIVE LINK) — Download from a shared link\n",
    "\n",
    "# Run this cell when you have a Google Drive shared link to a folder or ZIP of WAV files.\n",
    "# Supports:\n",
    "#   - A shared FOLDER link  (gdown downloads all files in the folder)\n",
    "#   - A shared FILE link    (single WAV or a ZIP archive that will be extracted)\n",
    "\n",
    "!pip install -q gdown\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "# -----------------------------\n",
    "# PASTE YOUR GOOGLE DRIVE LINK HERE\n",
    "# -----------------------------\n",
    "gdrive_link = \"https://drive.google.com/drive/folders/1haxHTVn_l9sfK-p2Pb0P1Npa2_K1teZ6\"\n",
    "\n",
    "# -----------------------------\n",
    "# LOCAL PATHS\n",
    "# -----------------------------\n",
    "run_root = \"/content/run_detector2\"\n",
    "download_dir = f\"{run_root}/download\"\n",
    "input_audio_dir = f\"{run_root}/audio\"\n",
    "output_csv_filepath = f\"{run_root}/explosion_results.csv\"\n",
    "\n",
    "Path(download_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(input_audio_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Detect if the link is a folder or a single file\n",
    "is_folder = '/folders/' in gdrive_link\n",
    "\n",
    "if is_folder:\n",
    "    print('Detected FOLDER link. Downloading all files...')\n",
    "    gdown.download_folder(gdrive_link, output=input_audio_dir, quiet=False)\n",
    "else:\n",
    "    print('Detected FILE link. Downloading...')\n",
    "    downloaded_file = gdown.download(gdrive_link, output=download_dir + '/', fuzzy=True, quiet=False)\n",
    "    # If it is a ZIP, extract it\n",
    "    if downloaded_file and downloaded_file.endswith('.zip'):\n",
    "        print('Extracting ZIP archive...')\n",
    "        with zipfile.ZipFile(downloaded_file, 'r') as zf:\n",
    "            zf.extractall(input_audio_dir)\n",
    "        print('Extraction complete.')\n",
    "    elif downloaded_file and downloaded_file.lower().endswith('.wav'):\n",
    "        import shutil\n",
    "        shutil.move(downloaded_file, os.path.join(input_audio_dir, os.path.basename(downloaded_file)))\n",
    "    else:\n",
    "        print(f'Downloaded file: {downloaded_file}')\n",
    "        print('If this is not a WAV or ZIP, please adjust the code.')\n",
    "\n",
    "# List downloaded WAVs\n",
    "wav_files = glob.glob(os.path.join(input_audio_dir, '**', '*.[wW][aA][vV]'), recursive=True)\n",
    "print(f'WAV files found: {len(wav_files)}')\n",
    "for f in wav_files[:5]:\n",
    "    print(' ', f)\n",
    "\n",
    "print('\\ninput_audio_dir:', input_audio_dir)\n",
    "print('output_csv_filepath:', output_csv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configuration (LOCAL ONLY)\n",
    "\n",
    "# Run this cell only if you're running locally.\n",
    "\n",
    "# -----------------------------\n",
    "# PATHS (Local)\n",
    "# -----------------------------\n",
    "input_audio_dir = \"/path/to/your/wav/folder\"\n",
    "output_csv_filepath = \"/path/to/your/wav/folder/explosion_results.csv\"\n",
    "\n",
    "print('input_audio_dir:', input_audio_dir)\n",
    "print('output_csv_filepath:', output_csv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-common",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configuration (COMMON — ALWAYS RUN)\n",
    "\n",
    "# Run this cell after you run ONE of the configuration cells above.\n",
    "\n",
    "# Configuration dictionary for all tunable thresholds\n",
    "DETECTOR_CONFIG = {\n",
    "    # Tier 1: Initial Event Detection\n",
    "    \"energy_threshold_db\": 20,  # dB above ambient noise level\n",
    "    \"broadband_check_bands\": [(100, 1000), (1000, 5000), (5000, 15000)],  # Hz frequency bands\n",
    "    \"broadband_energy_threshold\": 0.15,  # Min energy percentage per band\n",
    "    \n",
    "    # Tier 2: Primary Classification  \n",
    "    \"shockwave_rise_time_ms\": 5,  # Max rise time in milliseconds\n",
    "    \"bubble_pulse_search_window_ms\": 500,  # Search window after shockwave (ms)\n",
    "    \"bubble_pulse_min_period_ms\": 20,  # Min time between shockwave and bubble pulse\n",
    "    \"bubble_pulse_max_period_ms\": 200,  # Max time between shockwave and bubble pulse\n",
    "    \"bubble_pulse_amplitude_ratio\": 0.1,  # Min amplitude ratio (bubble/shockwave)\n",
    "    \"peak_prominence_factor\": 0.3,  # For secondary peak detection\n",
    "    \n",
    "    # Tier 3: Contextual Filtering (for future use)\n",
    "    \"repetition_interval_s\": 30,  # Time window for repetition checks\n",
    "    \n",
    "    # General parameters\n",
    "    \"sample_rate\": 22050,  # Target sample rate for analysis\n",
    "    \"frame_length_ms\": 50,  # Frame length for RMS analysis\n",
    "    \"min_event_duration_ms\": 10,  # Minimum event duration\n",
    "}\n",
    "\n",
    "# Dataset settings\n",
    "dataset_fileglob = '*.[wW][aA][vV]'\n",
    "\n",
    "# -----------------------------\n",
    "# FILE RANGE SELECTION\n",
    "# -----------------------------\n",
    "# Use these to process files in batches.\n",
    "# Examples:\n",
    "#   file_start = 0,    file_end = 1000   -> files 1 to 1000\n",
    "#   file_start = 1000, file_end = 2000   -> files 1001 to 2000\n",
    "#   file_start = 0,    file_end = None   -> ALL files\n",
    "file_start = 0     # 0-indexed start (inclusive)\n",
    "file_end = None    # 0-indexed end (exclusive). Set to None to process all remaining files.\n",
    "\n",
    "# -----------------------------\n",
    "# VALIDATE REQUIRED PATHS\n",
    "# -----------------------------\n",
    "_required = ['input_audio_dir', 'output_csv_filepath']\n",
    "_missing = [k for k in _required if k not in globals() or not globals()[k]]\n",
    "if _missing:\n",
    "    raise RuntimeError(\n",
    "        'Missing required path variables from one of the configuration cells: '\n",
    "        + ', '.join(_missing)\n",
    "    )\n",
    "\n",
    "Path(output_csv_filepath).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Discover WAV files\n",
    "wav_files_all = sorted(glob.glob(os.path.join(input_audio_dir, '**', dataset_fileglob), recursive=True))\n",
    "print(f'input_audio_dir: {input_audio_dir}')\n",
    "print(f'output_csv_filepath: {output_csv_filepath}')\n",
    "print(f'Total WAV files found: {len(wav_files_all)}')\n",
    "\n",
    "# Apply file range\n",
    "wav_files = wav_files_all[file_start:file_end]\n",
    "print(f'File range: [{file_start} : {file_end if file_end is not None else \"end\"}]  ->  {len(wav_files)} files selected')\n",
    "\n",
    "if wav_files:\n",
    "    print('First file:', os.path.basename(wav_files[0]))\n",
    "    print('Last file: ', os.path.basename(wav_files[-1]))\n",
    "if len(wav_files) == 0:\n",
    "    raise RuntimeError(\n",
    "        f'No WAV files in the selected range [{file_start}:{file_end}]. '\n",
    "        f'Total files available: {len(wav_files_all)}. '\n",
    "        'Check input_audio_dir, dataset_fileglob, or file_start/file_end.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detection-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Detection Logic (all tiers)\n",
    "\n",
    "def _tier1_energy_threshold(audio_data, sr, config):\n",
    "    \"\"\"\n",
    "    Tier 1, Rule 1: Energy Threshold Detection\n",
    "    Finds segments where acoustic energy dramatically exceeds baseline.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate short-term RMS energy\n",
    "    frame_length = int(config[\"frame_length_ms\"] * sr / 1000)\n",
    "    rms = librosa.feature.rms(y=audio_data, frame_length=frame_length, hop_length=frame_length//2)[0]\n",
    "    \n",
    "    # Convert to dB\n",
    "    rms_db = 20 * np.log10(rms + 1e-8)  # Add small value to avoid log(0)\n",
    "    \n",
    "    # Calculate baseline (ambient noise level)\n",
    "    baseline_db = np.median(rms_db)\n",
    "    \n",
    "    # Find high-energy segments\n",
    "    threshold_db = baseline_db + config[\"energy_threshold_db\"]\n",
    "    high_energy_frames = np.where(rms_db > threshold_db)[0]\n",
    "    \n",
    "    if len(high_energy_frames) == 0:\n",
    "        return {\n",
    "            'passed': False,\n",
    "            'reason': 'No high-energy transient found',\n",
    "            'baseline_db': baseline_db,\n",
    "            'threshold_db': threshold_db\n",
    "        }\n",
    "    \n",
    "    # Group consecutive frames into candidates\n",
    "    candidates = []\n",
    "    hop_length = frame_length // 2\n",
    "    \n",
    "    # Find continuous regions\n",
    "    frame_groups = []\n",
    "    current_group = [high_energy_frames[0]]\n",
    "    \n",
    "    for frame in high_energy_frames[1:]:\n",
    "        if frame == current_group[-1] + 1:\n",
    "            current_group.append(frame)\n",
    "        else:\n",
    "            frame_groups.append(current_group)\n",
    "            current_group = [frame]\n",
    "    frame_groups.append(current_group)\n",
    "    \n",
    "    # Convert frame groups to sample indices\n",
    "    for group in frame_groups:\n",
    "        start_frame = group[0]\n",
    "        end_frame = group[-1]\n",
    "        \n",
    "        start_idx = max(0, start_frame * hop_length - frame_length)\n",
    "        end_idx = min(len(audio_data), (end_frame + 1) * hop_length + frame_length)\n",
    "        \n",
    "        # Check minimum duration\n",
    "        duration_ms = (end_idx - start_idx) / sr * 1000\n",
    "        if duration_ms >= config[\"min_event_duration_ms\"]:\n",
    "            candidates.append({\n",
    "                'start_idx': start_idx,\n",
    "                'end_idx': end_idx,\n",
    "                'duration_ms': duration_ms,\n",
    "                'max_energy_db': np.max(rms_db[start_frame:end_frame+1])\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        'passed': len(candidates) > 0,\n",
    "        'candidates': candidates,\n",
    "        'baseline_db': baseline_db,\n",
    "        'threshold_db': threshold_db,\n",
    "        'reason': f'Found {len(candidates)} energy candidates' if candidates else 'No candidates meet minimum duration'\n",
    "    }\n",
    "\n",
    "\n",
    "def _tier1_broadband_check(audio_data, sr, candidate, config):\n",
    "    \"\"\"\n",
    "    Tier 1, Rule 2: Broadband Check\n",
    "    Verifies that significant energy is present across multiple frequency bands.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract candidate segment\n",
    "    segment = audio_data[candidate['start_idx']:candidate['end_idx']]\n",
    "    \n",
    "    # Compute FFT\n",
    "    fft = np.fft.fft(segment)\n",
    "    freqs = np.fft.fftfreq(len(segment), 1/sr)\n",
    "    magnitude = np.abs(fft)\n",
    "    \n",
    "    # Only consider positive frequencies\n",
    "    positive_freq_mask = freqs >= 0\n",
    "    freqs = freqs[positive_freq_mask]\n",
    "    magnitude = magnitude[positive_freq_mask]\n",
    "    \n",
    "    total_energy = np.sum(magnitude**2)\n",
    "    \n",
    "    # Check energy in each frequency band\n",
    "    bands_passed = 0\n",
    "    for low_freq, high_freq in config[\"broadband_check_bands\"]:\n",
    "        band_mask = (freqs >= low_freq) & (freqs <= high_freq)\n",
    "        band_energy = np.sum(magnitude[band_mask]**2)\n",
    "        band_energy_ratio = band_energy / total_energy\n",
    "        \n",
    "        if band_energy_ratio >= config[\"broadband_energy_threshold\"]:\n",
    "            bands_passed += 1\n",
    "    \n",
    "    # Require energy in at least 2 out of 3 frequency bands\n",
    "    return bands_passed >= 2\n",
    "\n",
    "\n",
    "def _tier2_shockwave_detection(segment, sr, config):\n",
    "    \"\"\"\n",
    "    Tier 2, Rule 3: Shockwave Detection\n",
    "    Analyzes the segment for extremely short rise time characteristic of shockwaves.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the absolute peak (potential shockwave)\n",
    "    peak_idx = np.argmax(np.abs(segment))\n",
    "    peak_amplitude = np.abs(segment[peak_idx])\n",
    "    \n",
    "    # Analyze rise time leading up to the peak\n",
    "    # Look backwards from peak to find 10% and 90% amplitude points\n",
    "    search_start = max(0, peak_idx - int(0.1 * sr))  # Search up to 100ms before peak\n",
    "    search_segment = segment[search_start:peak_idx+1]\n",
    "    search_amplitudes = np.abs(search_segment)\n",
    "    \n",
    "    # Find 10% and 90% amplitude points\n",
    "    amp_10_percent = 0.1 * peak_amplitude\n",
    "    amp_90_percent = 0.9 * peak_amplitude\n",
    "    \n",
    "    # Find last point below 10% threshold\n",
    "    below_10_mask = search_amplitudes < amp_10_percent\n",
    "    if not np.any(below_10_mask):\n",
    "        return {\n",
    "            'valid': False,\n",
    "            'reason': 'Cannot find 10% amplitude point for rise time calculation'\n",
    "        }\n",
    "    \n",
    "    idx_10_percent = np.where(below_10_mask)[0][-1]  # Last point below 10%\n",
    "    \n",
    "    # Find first point above 90% threshold after the 10% point\n",
    "    above_90_mask = search_amplitudes[idx_10_percent:] > amp_90_percent\n",
    "    if not np.any(above_90_mask):\n",
    "        return {\n",
    "            'valid': False,\n",
    "            'reason': 'Cannot find 90% amplitude point for rise time calculation'\n",
    "        }\n",
    "    \n",
    "    idx_90_percent = idx_10_percent + np.where(above_90_mask)[0][0]\n",
    "    \n",
    "    # Calculate rise time\n",
    "    rise_time_samples = idx_90_percent - idx_10_percent\n",
    "    rise_time_ms = (rise_time_samples / sr) * 1000\n",
    "    \n",
    "    # Check if rise time is sufficiently short for a shockwave\n",
    "    if rise_time_ms > config[\"shockwave_rise_time_ms\"]:\n",
    "        return {\n",
    "            'valid': False,\n",
    "            'reason': f'Rise time too slow ({rise_time_ms:.1f}ms > {config[\"shockwave_rise_time_ms\"]}ms threshold)'\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'valid': True,\n",
    "        'peak_idx': peak_idx,\n",
    "        'peak_amplitude': peak_amplitude,\n",
    "        'rise_time_ms': rise_time_ms,\n",
    "        'reason': f'Valid shockwave detected (rise time: {rise_time_ms:.1f}ms)'\n",
    "    }\n",
    "\n",
    "\n",
    "def _tier2_bubble_pulse_search(segment, sr, shockwave_result, config):\n",
    "    \"\"\"\n",
    "    Tier 2, Rule 4: Bubble Pulse Search\n",
    "    Searches for secondary peak (bubble pulse) after the shockwave.\n",
    "    \"\"\"\n",
    "    \n",
    "    shockwave_idx = shockwave_result['peak_idx']\n",
    "    shockwave_amplitude = shockwave_result['peak_amplitude']\n",
    "    \n",
    "    # Define search window after shockwave\n",
    "    search_start_idx = shockwave_idx + int(config[\"bubble_pulse_min_period_ms\"] * sr / 1000)\n",
    "    search_end_idx = min(len(segment), \n",
    "                        shockwave_idx + int(config[\"bubble_pulse_search_window_ms\"] * sr / 1000))\n",
    "    \n",
    "    if search_start_idx >= search_end_idx or search_start_idx >= len(segment):\n",
    "        return {\n",
    "            'found': False,\n",
    "            'reason': 'Search window too short or extends beyond segment'\n",
    "        }\n",
    "    \n",
    "    search_segment = segment[search_start_idx:search_end_idx]\n",
    "    \n",
    "    # Find peaks in the search region\n",
    "    min_height = config[\"bubble_pulse_amplitude_ratio\"] * shockwave_amplitude\n",
    "    prominence = config[\"peak_prominence_factor\"] * min_height\n",
    "    \n",
    "    peaks, properties = scipy.signal.find_peaks(\n",
    "        np.abs(search_segment), \n",
    "        height=min_height,\n",
    "        prominence=prominence\n",
    "    )\n",
    "    \n",
    "    if len(peaks) == 0:\n",
    "        return {\n",
    "            'found': False,\n",
    "            'reason': f'No secondary peaks found above {config[\"bubble_pulse_amplitude_ratio\"]*100:.0f}% of shockwave amplitude'\n",
    "        }\n",
    "    \n",
    "    # Select the most prominent peak as bubble pulse\n",
    "    peak_heights = properties['peak_heights']\n",
    "    most_prominent_idx = np.argmax(peak_heights)\n",
    "    bubble_peak_idx = peaks[most_prominent_idx]\n",
    "    bubble_amplitude = peak_heights[most_prominent_idx]\n",
    "    \n",
    "    # Convert to absolute index in segment\n",
    "    bubble_idx_absolute = search_start_idx + bubble_peak_idx\n",
    "    \n",
    "    # Calculate bubble period\n",
    "    period_samples = bubble_idx_absolute - shockwave_idx\n",
    "    period_ms = (period_samples / sr) * 1000\n",
    "    \n",
    "    return {\n",
    "        'found': True,\n",
    "        'bubble_idx': bubble_idx_absolute,\n",
    "        'bubble_amplitude': bubble_amplitude,\n",
    "        'period_ms': period_ms,\n",
    "        'amplitude_ratio': bubble_amplitude / shockwave_amplitude,\n",
    "        'reason': f'Bubble pulse found at {period_ms:.1f}ms after shockwave'\n",
    "    }\n",
    "\n",
    "\n",
    "def _tier2_physical_plausibility(bubble_result, config):\n",
    "    \"\"\"\n",
    "    Tier 2, Rule 5: Physical Plausibility Check\n",
    "    Verifies that bubble period falls within physically realistic range.\n",
    "    \"\"\"\n",
    "    \n",
    "    period_ms = bubble_result['period_ms']\n",
    "    min_period = config[\"bubble_pulse_min_period_ms\"]\n",
    "    max_period = config[\"bubble_pulse_max_period_ms\"]\n",
    "    \n",
    "    return min_period <= period_ms <= max_period\n",
    "\n",
    "\n",
    "def analyze_audio_for_explosion(audio_path, config=None):\n",
    "    \"\"\"\n",
    "    Analyzes an audio file for dynamite explosion signatures based on the report.\n",
    "    \n",
    "    Args:\n",
    "        audio_path (str): Path to the audio file\n",
    "        config (dict): Configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis results with detection status and metrics\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = DETECTOR_CONFIG\n",
    "    \n",
    "    try:\n",
    "        # Load audio file\n",
    "        audio_data, sr = librosa.load(audio_path, sr=config[\"sample_rate\"])\n",
    "        \n",
    "        if len(audio_data) == 0:\n",
    "            return {\n",
    "                'is_explosion': False,\n",
    "                'reason': 'Empty audio file',\n",
    "                'file_path': audio_path,\n",
    "                'sample_rate': sr\n",
    "            }\n",
    "            \n",
    "        print(f\"Loaded audio: {len(audio_data)/sr:.2f}s at {sr}Hz\")\n",
    "        \n",
    "        # ==================== TIER 1: INITIAL EVENT DETECTION ====================\n",
    "        print(\"\\n--- TIER 1: Initial Event Detection ---\")\n",
    "        \n",
    "        # Rule 1: Energy Threshold Detection\n",
    "        tier1_result = _tier1_energy_threshold(audio_data, sr, config)\n",
    "        if not tier1_result['passed']:\n",
    "            return {\n",
    "                'is_explosion': False,\n",
    "                'reason': tier1_result['reason'],\n",
    "                'file_path': audio_path,\n",
    "                'sample_rate': sr,\n",
    "                'tier1_result': tier1_result\n",
    "            }\n",
    "        \n",
    "        candidates = tier1_result['candidates']\n",
    "        print(f\"Found {len(candidates)} high-energy candidates\")\n",
    "        \n",
    "        # Rule 2: Broadband Check\n",
    "        broadband_candidates = []\n",
    "        for candidate in candidates:\n",
    "            if _tier1_broadband_check(audio_data, sr, candidate, config):\n",
    "                broadband_candidates.append(candidate)\n",
    "        \n",
    "        if not broadband_candidates:\n",
    "            return {\n",
    "                'is_explosion': False,\n",
    "                'reason': 'No broadband high-energy transients found',\n",
    "                'file_path': audio_path,\n",
    "                'sample_rate': sr,\n",
    "                'tier1_result': tier1_result\n",
    "            }\n",
    "            \n",
    "        print(f\"Found {len(broadband_candidates)} broadband candidates\")\n",
    "        \n",
    "        # ==================== TIER 2: PRIMARY CLASSIFICATION ====================\n",
    "        print(\"\\n--- TIER 2: Primary Classification ---\")\n",
    "        \n",
    "        for i, candidate in enumerate(broadband_candidates):\n",
    "            print(f\"\\nAnalyzing candidate {i+1}/{len(broadband_candidates)}\")\n",
    "            \n",
    "            # Extract candidate segment\n",
    "            start_idx = candidate['start_idx']\n",
    "            end_idx = candidate['end_idx']\n",
    "            segment = audio_data[start_idx:end_idx]\n",
    "            \n",
    "            # Rule 3: Shockwave Detection\n",
    "            shockwave_result = _tier2_shockwave_detection(segment, sr, config)\n",
    "            if not shockwave_result['valid']:\n",
    "                print(f\"  X Candidate {i+1}: {shockwave_result['reason']}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"  V Valid shockwave detected (rise time: {shockwave_result['rise_time_ms']:.1f}ms)\")\n",
    "            \n",
    "            # Rule 4: Bubble Pulse Search\n",
    "            bubble_result = _tier2_bubble_pulse_search(segment, sr, shockwave_result, config)\n",
    "            if not bubble_result['found']:\n",
    "                print(f\"  X Candidate {i+1}: {bubble_result['reason']}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"  V Bubble pulse found (period: {bubble_result['period_ms']:.1f}ms)\")\n",
    "            \n",
    "            # Rule 5: Physical Plausibility Check\n",
    "            if not _tier2_physical_plausibility(bubble_result, config):\n",
    "                print(f\"  X Candidate {i+1}: Bubble period outside physically plausible range\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"  V Physical plausibility confirmed\")\n",
    "            \n",
    "            # If we reach here, we have a valid explosion detection!\n",
    "            explosion_time = (start_idx + shockwave_result['peak_idx']) / sr\n",
    "            \n",
    "            return {\n",
    "                'is_explosion': True,\n",
    "                'reason': 'Shockwave and plausible bubble pulse detected',\n",
    "                'file_path': audio_path,\n",
    "                'sample_rate': sr,\n",
    "                'explosion_time_s': explosion_time,\n",
    "                'metrics': {\n",
    "                    'shockwave_time_s': explosion_time,\n",
    "                    'bubble_period_ms': bubble_result['period_ms'],\n",
    "                    'rise_time_ms': shockwave_result['rise_time_ms'],\n",
    "                    'shockwave_amplitude': shockwave_result['peak_amplitude'],\n",
    "                    'bubble_amplitude': bubble_result['bubble_amplitude'],\n",
    "                    'amplitude_ratio': bubble_result['amplitude_ratio']\n",
    "                },\n",
    "                'detection_data': {\n",
    "                    'audio_segment': segment,\n",
    "                    'segment_start_time': start_idx / sr,\n",
    "                    'shockwave_idx': shockwave_result['peak_idx'],\n",
    "                    'bubble_idx': bubble_result['bubble_idx'],\n",
    "                    'sample_rate': sr\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # No valid explosions found\n",
    "        return {\n",
    "            'is_explosion': False,\n",
    "            'reason': 'No candidates passed all explosion verification tests',\n",
    "            'file_path': audio_path,\n",
    "            'sample_rate': sr,\n",
    "            'candidates_analyzed': len(broadband_candidates)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'is_explosion': False,\n",
    "            'reason': f'Error analyzing audio: {str(e)}',\n",
    "            'file_path': audio_path\n",
    "        }\n",
    "\n",
    "\n",
    "def plot_detection_details(audio_data, sr, metrics):\n",
    "    \"\"\"\n",
    "    Creates a two-panel visualization showing the detected explosion signature.\n",
    "    \n",
    "    Args:\n",
    "        audio_data (np.array): Audio data\n",
    "        sr (int): Sample rate  \n",
    "        metrics (dict): Detection metrics and data\n",
    "    \"\"\"\n",
    "    \n",
    "    detection_data = metrics['detection_data']\n",
    "    segment = detection_data['audio_segment']\n",
    "    shockwave_idx = detection_data['shockwave_idx'] \n",
    "    bubble_idx = detection_data['bubble_idx']\n",
    "    segment_start_time = detection_data['segment_start_time']\n",
    "    \n",
    "    # Create time arrays\n",
    "    segment_time = np.arange(len(segment)) / sr + segment_start_time\n",
    "    full_time = np.arange(len(audio_data)) / sr\n",
    "    \n",
    "    # Create figure with 2 subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    fig.suptitle('Dynamite Explosion Detection Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # ==================== WAVEFORM PLOT ====================\n",
    "    ax1.plot(segment_time, segment, 'b-', linewidth=1, alpha=0.7, label='Audio Waveform')\n",
    "    \n",
    "    # Mark shockwave peak\n",
    "    shockwave_time = segment_time[shockwave_idx]\n",
    "    ax1.axvline(shockwave_time, color='red', linewidth=2, linestyle='--', alpha=0.8)\n",
    "    ax1.plot(shockwave_time, segment[shockwave_idx], 'ro', markersize=8, label='Shockwave Peak')\n",
    "    ax1.text(shockwave_time, segment[shockwave_idx] + 0.1*np.max(np.abs(segment)), \n",
    "             'Shockwave Peak', ha='center', va='bottom', fontweight='bold', color='red')\n",
    "    \n",
    "    # Mark bubble pulse peak\n",
    "    bubble_time = segment_time[bubble_idx]\n",
    "    ax1.axvline(bubble_time, color='orange', linewidth=2, linestyle='--', alpha=0.8)\n",
    "    ax1.plot(bubble_time, segment[bubble_idx], 'o', color='orange', markersize=8, label='Bubble Pulse')\n",
    "    ax1.text(bubble_time, segment[bubble_idx] + 0.1*np.max(np.abs(segment)), \n",
    "             'First Bubble Pulse', ha='center', va='bottom', fontweight='bold', color='orange')\n",
    "    \n",
    "    # Add double-headed arrow for bubble period\n",
    "    arrow_y = 0.8 * np.max(np.abs(segment))\n",
    "    ax1.annotate('', xy=(bubble_time, arrow_y), xytext=(shockwave_time, arrow_y),\n",
    "                arrowprops=dict(arrowstyle='<->', color='purple', lw=2))\n",
    "    bubble_period_ms = metrics[\"metrics\"][\"bubble_period_ms\"]\n",
    "    ax1.text((shockwave_time + bubble_time) / 2, arrow_y + 0.05*np.max(np.abs(segment)),\n",
    "             f'Bubble Period (tpuls)\\n{bubble_period_ms:.1f}ms', \n",
    "             ha='center', va='bottom', fontweight='bold', color='purple',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "    \n",
    "    ax1.set_xlabel('Time (seconds)', fontweight='bold')\n",
    "    ax1.set_ylabel('Amplitude', fontweight='bold')\n",
    "    ax1.set_title('Annotated Waveform - Explosion Event Detection', fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # ==================== SPECTROGRAM PLOT ====================\n",
    "    # Compute spectrogram\n",
    "    D = librosa.stft(segment)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    \n",
    "    # Plot spectrogram\n",
    "    img = librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='hz', \n",
    "                                   ax=ax2, cmap='viridis')\n",
    "    \n",
    "    # Adjust time axis to match segment timing\n",
    "    ax2_xlim = ax2.get_xlim()\n",
    "    time_offset = segment_start_time\n",
    "    ax2.set_xlim([ax2_xlim[0] + time_offset, ax2_xlim[1] + time_offset])\n",
    "    \n",
    "    # Mark explosion time\n",
    "    ax2.axvline(shockwave_time, color='red', linewidth=3, linestyle='-', alpha=0.9)\n",
    "    ax2.text(shockwave_time + 0.01, ax2.get_ylim()[1] * 0.9, \n",
    "             'Broadband Shockwave Event', rotation=90, ha='left', va='top', \n",
    "             fontweight='bold', color='red',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "    \n",
    "    # Add bracket for reverberant tail\n",
    "    tail_start = bubble_time\n",
    "    tail_end = segment_time[-1]\n",
    "    tail_y = ax2.get_ylim()[1] * 0.7\n",
    "    \n",
    "    # Draw bracket\n",
    "    bracket_height = ax2.get_ylim()[1] * 0.05\n",
    "    ax2.plot([tail_start, tail_start], [tail_y - bracket_height, tail_y + bracket_height], \n",
    "             'k-', linewidth=2)\n",
    "    ax2.plot([tail_end, tail_end], [tail_y - bracket_height, tail_y + bracket_height], \n",
    "             'k-', linewidth=2)  \n",
    "    ax2.plot([tail_start, tail_end], [tail_y, tail_y], 'k-', linewidth=2)\n",
    "    \n",
    "    ax2.text((tail_start + tail_end) / 2, tail_y + bracket_height * 2,\n",
    "             'Reverberant Tail', ha='center', va='bottom', fontweight='bold',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "    \n",
    "    ax2.set_title('Annotated Spectrogram - Frequency Domain Analysis', fontweight='bold')\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "    cbar.set_label('Magnitude (dB)', fontweight='bold')\n",
    "    \n",
    "    # Add detection summary text box\n",
    "    summary_text = (f\"Detection Summary:\\n\"\n",
    "                    f\"  Explosion detected at {metrics['explosion_time_s']:.2f}s\\n\"\n",
    "                    f\"  Shockwave rise time: {metrics['metrics']['rise_time_ms']:.1f}ms\\n\"\n",
    "                    f\"  Bubble period: {metrics['metrics']['bubble_period_ms']:.1f}ms\\n\"\n",
    "                    f\"  Amplitude ratio: {metrics['metrics']['amplitude_ratio']:.2f}\\n\"\n",
    "                    f\"  Classification: POSITIVE DETECTION\")\n",
    "    \n",
    "    props = dict(boxstyle='round', facecolor='lightgreen', alpha=0.8)\n",
    "    ax1.text(0.02, 0.98, summary_text, transform=ax1.transAxes, fontsize=10,\n",
    "             verticalalignment='top', bbox=props, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "print('Detection logic loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run detector on all WAV files and write inference CSV\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Sanity checks\n",
    "audio_root = Path(str(input_audio_dir))\n",
    "print('input_audio_dir exists:', audio_root.exists(), 'is_dir:', audio_root.is_dir())\n",
    "\n",
    "if not audio_root.exists() or not audio_root.is_dir():\n",
    "    raise RuntimeError(f'input_audio_dir is not a readable directory: {input_audio_dir}')\n",
    "\n",
    "print(f'WAV files to analyze: {len(wav_files)}  (range [{file_start}:{file_end if file_end is not None else \"end\"}])')\n",
    "if len(wav_files) == 0:\n",
    "    raise RuntimeError('No WAV files found. Check input_audio_dir and dataset_fileglob.')\n",
    "\n",
    "# Build batch-aware output CSV path so batches don't overwrite each other\n",
    "_end_label = file_end if file_end is not None else len(wav_files_all)\n",
    "batch_csv_filepath = str(\n",
    "    Path(output_csv_filepath).with_name(\n",
    "        Path(output_csv_filepath).stem + f'_{file_start}_{_end_label}.csv'\n",
    "    )\n",
    ")\n",
    "print(f'Batch CSV: {batch_csv_filepath}')\n",
    "\n",
    "# Run detection on every file\n",
    "all_results = []\n",
    "detections = []\n",
    "\n",
    "for i, wav_path in enumerate(wav_files):\n",
    "    global_idx = file_start + i\n",
    "    print(f'\\n[{global_idx + 1}/{len(wav_files_all)}] {os.path.basename(wav_path)}')\n",
    "    result = analyze_audio_for_explosion(wav_path, DETECTOR_CONFIG)\n",
    "    all_results.append(result)\n",
    "    \n",
    "    status = 'EXPLOSION' if result['is_explosion'] else 'no detection'\n",
    "    print(f'  -> {status}: {result[\"reason\"]}')\n",
    "    \n",
    "    if result['is_explosion']:\n",
    "        detections.append(result)\n",
    "\n",
    "# Build results DataFrame\n",
    "rows = []\n",
    "for r in all_results:\n",
    "    row = {\n",
    "        'filename': os.path.basename(r['file_path']),\n",
    "        'filepath': r['file_path'],\n",
    "        'is_explosion': r['is_explosion'],\n",
    "        'reason': r['reason'],\n",
    "    }\n",
    "    if r['is_explosion']:\n",
    "        row['explosion_time_s'] = r.get('explosion_time_s')\n",
    "        row['rise_time_ms'] = r['metrics']['rise_time_ms']\n",
    "        row['bubble_period_ms'] = r['metrics']['bubble_period_ms']\n",
    "        row['shockwave_amplitude'] = r['metrics']['shockwave_amplitude']\n",
    "        row['bubble_amplitude'] = r['metrics']['bubble_amplitude']\n",
    "        row['amplitude_ratio'] = r['metrics']['amplitude_ratio']\n",
    "    rows.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "\n",
    "# Write batch CSV\n",
    "results_df.to_csv(batch_csv_filepath, index=False)\n",
    "\n",
    "# Also append to the main CSV (create if first batch, append otherwise)\n",
    "if os.path.exists(output_csv_filepath):\n",
    "    results_df.to_csv(output_csv_filepath, mode='a', header=False, index=False)\n",
    "    print(f'Appended {len(results_df)} rows to: {output_csv_filepath}')\n",
    "else:\n",
    "    results_df.to_csv(output_csv_filepath, index=False)\n",
    "    print(f'Created: {output_csv_filepath}')\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('DETECTION COMPLETE')\n",
    "print('=' * 60)\n",
    "print(f'Batch range: [{file_start} : {file_end if file_end is not None else \"end\"}]')\n",
    "print(f'Files analyzed: {len(all_results)}')\n",
    "print(f'Explosions detected: {len(detections)}')\n",
    "print(f'Batch CSV: {batch_csv_filepath}')\n",
    "print(f'Main CSV:  {output_csv_filepath}')\n",
    "\n",
    "# Optionally copy CSV back to Drive (only if configured)\n",
    "if 'output_csv_drive' in globals() and output_csv_drive:\n",
    "    import subprocess\n",
    "    print('Copying results CSV back to Drive...')\n",
    "    subprocess.run(['cp', '-f', output_csv_filepath, output_csv_drive], check=True)\n",
    "    print('Done. Wrote:', output_csv_drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plot detection details for each positive detection\n",
    "\n",
    "if not detections:\n",
    "    print('No explosions detected. Nothing to plot.')\n",
    "else:\n",
    "    for i, result in enumerate(detections):\n",
    "        print(f'\\nPlotting detection {i+1}/{len(detections)}: {os.path.basename(result[\"file_path\"])}')\n",
    "        audio_data, sr = librosa.load(result['file_path'], sr=DETECTOR_CONFIG['sample_rate'])\n",
    "        fig = plot_detection_details(audio_data, sr, result)\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plot detections over time (detections/hour)\n",
    "\n",
    "import re\n",
    "\n",
    "csv_path = output_csv_filepath\n",
    "df = pd.read_csv(csv_path)\n",
    "print('rows:', len(df))\n",
    "print('columns:', list(df.columns))\n",
    "\n",
    "# Only keep positive detections\n",
    "df = df[df['is_explosion'] == True].copy()\n",
    "\n",
    "if df.empty:\n",
    "    print('No positive detections to plot.')\n",
    "else:\n",
    "    # Parse datetime from filename like YYYYMMDD_HHMMSS\n",
    "    _dt_re = re.compile(r'(\\d{8})_(\\d{6})')\n",
    "\n",
    "    def extract_dt(fname: str):\n",
    "        m = _dt_re.search(str(fname))\n",
    "        if not m:\n",
    "            return pd.NaT\n",
    "        return pd.to_datetime(m.group(1) + m.group(2), format='%Y%m%d%H%M%S', errors='coerce')\n",
    "\n",
    "    df['dt'] = df['filename'].apply(extract_dt)\n",
    "    plot_df = df.dropna(subset=['dt']).copy()\n",
    "\n",
    "    if plot_df.empty:\n",
    "        print('No rows had a parseable datetime in filename. Adjust extract_dt() regex/format.')\n",
    "    else:\n",
    "        plot_df = plot_df.set_index('dt').sort_index()\n",
    "\n",
    "        detections_per_hour = plot_df['filename'].resample('1h').count()\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        detections_per_hour.plot()\n",
    "        plt.title('Explosion Detections per Hour')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Detections / hour')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Daily totals\n",
    "        daily = plot_df['filename'].resample('1D').count()\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        daily.plot()\n",
    "        plt.title('Explosion Detections per Day')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Detections / day')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
